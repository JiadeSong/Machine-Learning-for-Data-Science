{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb104423",
   "metadata": {},
   "source": [
    "<center><h1>DSCI-552 HW_8</h1></center>\n",
    "<br>\n",
    "<center><font size=\"4\">Name: Jiade Song    GitHubID: JiadeSong     USCID: 9019610285 </font></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd76665",
   "metadata": {},
   "source": [
    "<center><font size=\"4\">1. Supervised, Semi-Supervised, and Unsupervised Learning</font></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85443e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import random\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn.semi_supervised import SelfTrainingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import plot_roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.cluster import SpectralClustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1cf087",
   "metadata": {},
   "source": [
    "### (b) Monte-Carlo Simulation: Repeat the following procedures for supervised, unsupervised, and semi-supervised learning M = 30 times, and use randomly selected train and test data (make sure you use 20% of both the positve and negative classes as the test set). Then compare the average scores (accuracy, precision, recall, F1-score, and AUC) that you obtain from each algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df7474fd",
   "metadata": {},
   "source": [
    "#### i. Supervised Learning: Train an L1-penalized SVM to classify the data. Use 5 fold cross validation to choose the penalty parameter. Use normalized data. Report the average accuracy, precision, recall, F1-score, and AUC, for both training and test sets over your M runs. Plot the ROC and report the confusion matrix for training and testing in one of the runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6beff1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_name = ['ID','Diagnosis']\n",
    "feature_names = ['radius','texture' ,'perimeter','area','smoothness','compactness','concavity',\\\n",
    "                 'concave_points' ,'symmetry','fractal_dimension']\n",
    "for i in feature_names:\n",
    "    for j in ['Mean', 'SE', 'Worst']:\n",
    "        this_column = j+'_'+i\n",
    "        column_name += [this_column]\n",
    "        \n",
    "file_path = r'../../Data/Data/wdbc.data'\n",
    "dataset = pd.read_csv(file_path, delimiter=\",\",names=column_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36c70a0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Diagnosis</th>\n",
       "      <th>Mean_radius</th>\n",
       "      <th>SE_radius</th>\n",
       "      <th>Worst_radius</th>\n",
       "      <th>Mean_texture</th>\n",
       "      <th>SE_texture</th>\n",
       "      <th>Worst_texture</th>\n",
       "      <th>Mean_perimeter</th>\n",
       "      <th>SE_perimeter</th>\n",
       "      <th>...</th>\n",
       "      <th>Worst_concavity</th>\n",
       "      <th>Mean_concave_points</th>\n",
       "      <th>SE_concave_points</th>\n",
       "      <th>Worst_concave_points</th>\n",
       "      <th>Mean_symmetry</th>\n",
       "      <th>SE_symmetry</th>\n",
       "      <th>Worst_symmetry</th>\n",
       "      <th>Mean_fractal_dimension</th>\n",
       "      <th>SE_fractal_dimension</th>\n",
       "      <th>Worst_fractal_dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>25.380</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>24.990</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>23.570</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>14.910</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>22.540</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>926424</td>\n",
       "      <td>M</td>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>...</td>\n",
       "      <td>25.450</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>926682</td>\n",
       "      <td>M</td>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>...</td>\n",
       "      <td>23.690</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>926954</td>\n",
       "      <td>M</td>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>...</td>\n",
       "      <td>18.980</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>927241</td>\n",
       "      <td>M</td>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>...</td>\n",
       "      <td>25.740</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>92751</td>\n",
       "      <td>B</td>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>9.456</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID Diagnosis  Mean_radius  SE_radius  Worst_radius  Mean_texture  \\\n",
       "0      842302         M        17.99      10.38        122.80        1001.0   \n",
       "1      842517         M        20.57      17.77        132.90        1326.0   \n",
       "2    84300903         M        19.69      21.25        130.00        1203.0   \n",
       "3    84348301         M        11.42      20.38         77.58         386.1   \n",
       "4    84358402         M        20.29      14.34        135.10        1297.0   \n",
       "..        ...       ...          ...        ...           ...           ...   \n",
       "564    926424         M        21.56      22.39        142.00        1479.0   \n",
       "565    926682         M        20.13      28.25        131.20        1261.0   \n",
       "566    926954         M        16.60      28.08        108.30         858.1   \n",
       "567    927241         M        20.60      29.33        140.10        1265.0   \n",
       "568     92751         B         7.76      24.54         47.92         181.0   \n",
       "\n",
       "     SE_texture  Worst_texture  Mean_perimeter  SE_perimeter  ...  \\\n",
       "0       0.11840        0.27760         0.30010       0.14710  ...   \n",
       "1       0.08474        0.07864         0.08690       0.07017  ...   \n",
       "2       0.10960        0.15990         0.19740       0.12790  ...   \n",
       "3       0.14250        0.28390         0.24140       0.10520  ...   \n",
       "4       0.10030        0.13280         0.19800       0.10430  ...   \n",
       "..          ...            ...             ...           ...  ...   \n",
       "564     0.11100        0.11590         0.24390       0.13890  ...   \n",
       "565     0.09780        0.10340         0.14400       0.09791  ...   \n",
       "566     0.08455        0.10230         0.09251       0.05302  ...   \n",
       "567     0.11780        0.27700         0.35140       0.15200  ...   \n",
       "568     0.05263        0.04362         0.00000       0.00000  ...   \n",
       "\n",
       "     Worst_concavity  Mean_concave_points  SE_concave_points  \\\n",
       "0             25.380                17.33             184.60   \n",
       "1             24.990                23.41             158.80   \n",
       "2             23.570                25.53             152.50   \n",
       "3             14.910                26.50              98.87   \n",
       "4             22.540                16.67             152.20   \n",
       "..               ...                  ...                ...   \n",
       "564           25.450                26.40             166.10   \n",
       "565           23.690                38.25             155.00   \n",
       "566           18.980                34.12             126.70   \n",
       "567           25.740                39.42             184.60   \n",
       "568            9.456                30.37              59.16   \n",
       "\n",
       "     Worst_concave_points  Mean_symmetry  SE_symmetry  Worst_symmetry  \\\n",
       "0                  2019.0        0.16220      0.66560          0.7119   \n",
       "1                  1956.0        0.12380      0.18660          0.2416   \n",
       "2                  1709.0        0.14440      0.42450          0.4504   \n",
       "3                   567.7        0.20980      0.86630          0.6869   \n",
       "4                  1575.0        0.13740      0.20500          0.4000   \n",
       "..                    ...            ...          ...             ...   \n",
       "564                2027.0        0.14100      0.21130          0.4107   \n",
       "565                1731.0        0.11660      0.19220          0.3215   \n",
       "566                1124.0        0.11390      0.30940          0.3403   \n",
       "567                1821.0        0.16500      0.86810          0.9387   \n",
       "568                 268.6        0.08996      0.06444          0.0000   \n",
       "\n",
       "     Mean_fractal_dimension  SE_fractal_dimension  Worst_fractal_dimension  \n",
       "0                    0.2654                0.4601                  0.11890  \n",
       "1                    0.1860                0.2750                  0.08902  \n",
       "2                    0.2430                0.3613                  0.08758  \n",
       "3                    0.2575                0.6638                  0.17300  \n",
       "4                    0.1625                0.2364                  0.07678  \n",
       "..                      ...                   ...                      ...  \n",
       "564                  0.2216                0.2060                  0.07115  \n",
       "565                  0.1628                0.2572                  0.06637  \n",
       "566                  0.1418                0.2218                  0.07820  \n",
       "567                  0.2650                0.4087                  0.12400  \n",
       "568                  0.0000                0.2871                  0.07039  \n",
       "\n",
       "[569 rows x 32 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35fd250d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dia_data = dataset.drop(labels=['ID'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c13584eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Diagnosis</th>\n",
       "      <th>Mean_radius</th>\n",
       "      <th>SE_radius</th>\n",
       "      <th>Worst_radius</th>\n",
       "      <th>Mean_texture</th>\n",
       "      <th>SE_texture</th>\n",
       "      <th>Worst_texture</th>\n",
       "      <th>Mean_perimeter</th>\n",
       "      <th>SE_perimeter</th>\n",
       "      <th>Worst_perimeter</th>\n",
       "      <th>...</th>\n",
       "      <th>Worst_concavity</th>\n",
       "      <th>Mean_concave_points</th>\n",
       "      <th>SE_concave_points</th>\n",
       "      <th>Worst_concave_points</th>\n",
       "      <th>Mean_symmetry</th>\n",
       "      <th>SE_symmetry</th>\n",
       "      <th>Worst_symmetry</th>\n",
       "      <th>Mean_fractal_dimension</th>\n",
       "      <th>SE_fractal_dimension</th>\n",
       "      <th>Worst_fractal_dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>...</td>\n",
       "      <td>25.380</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>...</td>\n",
       "      <td>24.990</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>...</td>\n",
       "      <td>23.570</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>...</td>\n",
       "      <td>14.910</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>...</td>\n",
       "      <td>22.540</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>M</td>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>...</td>\n",
       "      <td>25.450</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>M</td>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>...</td>\n",
       "      <td>23.690</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>M</td>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>...</td>\n",
       "      <td>18.980</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>M</td>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>...</td>\n",
       "      <td>25.740</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>B</td>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>...</td>\n",
       "      <td>9.456</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Diagnosis  Mean_radius  SE_radius  Worst_radius  Mean_texture  SE_texture  \\\n",
       "0           M        17.99      10.38        122.80        1001.0     0.11840   \n",
       "1           M        20.57      17.77        132.90        1326.0     0.08474   \n",
       "2           M        19.69      21.25        130.00        1203.0     0.10960   \n",
       "3           M        11.42      20.38         77.58         386.1     0.14250   \n",
       "4           M        20.29      14.34        135.10        1297.0     0.10030   \n",
       "..        ...          ...        ...           ...           ...         ...   \n",
       "564         M        21.56      22.39        142.00        1479.0     0.11100   \n",
       "565         M        20.13      28.25        131.20        1261.0     0.09780   \n",
       "566         M        16.60      28.08        108.30         858.1     0.08455   \n",
       "567         M        20.60      29.33        140.10        1265.0     0.11780   \n",
       "568         B         7.76      24.54         47.92         181.0     0.05263   \n",
       "\n",
       "     Worst_texture  Mean_perimeter  SE_perimeter  Worst_perimeter  ...  \\\n",
       "0          0.27760         0.30010       0.14710           0.2419  ...   \n",
       "1          0.07864         0.08690       0.07017           0.1812  ...   \n",
       "2          0.15990         0.19740       0.12790           0.2069  ...   \n",
       "3          0.28390         0.24140       0.10520           0.2597  ...   \n",
       "4          0.13280         0.19800       0.10430           0.1809  ...   \n",
       "..             ...             ...           ...              ...  ...   \n",
       "564        0.11590         0.24390       0.13890           0.1726  ...   \n",
       "565        0.10340         0.14400       0.09791           0.1752  ...   \n",
       "566        0.10230         0.09251       0.05302           0.1590  ...   \n",
       "567        0.27700         0.35140       0.15200           0.2397  ...   \n",
       "568        0.04362         0.00000       0.00000           0.1587  ...   \n",
       "\n",
       "     Worst_concavity  Mean_concave_points  SE_concave_points  \\\n",
       "0             25.380                17.33             184.60   \n",
       "1             24.990                23.41             158.80   \n",
       "2             23.570                25.53             152.50   \n",
       "3             14.910                26.50              98.87   \n",
       "4             22.540                16.67             152.20   \n",
       "..               ...                  ...                ...   \n",
       "564           25.450                26.40             166.10   \n",
       "565           23.690                38.25             155.00   \n",
       "566           18.980                34.12             126.70   \n",
       "567           25.740                39.42             184.60   \n",
       "568            9.456                30.37              59.16   \n",
       "\n",
       "     Worst_concave_points  Mean_symmetry  SE_symmetry  Worst_symmetry  \\\n",
       "0                  2019.0        0.16220      0.66560          0.7119   \n",
       "1                  1956.0        0.12380      0.18660          0.2416   \n",
       "2                  1709.0        0.14440      0.42450          0.4504   \n",
       "3                   567.7        0.20980      0.86630          0.6869   \n",
       "4                  1575.0        0.13740      0.20500          0.4000   \n",
       "..                    ...            ...          ...             ...   \n",
       "564                2027.0        0.14100      0.21130          0.4107   \n",
       "565                1731.0        0.11660      0.19220          0.3215   \n",
       "566                1124.0        0.11390      0.30940          0.3403   \n",
       "567                1821.0        0.16500      0.86810          0.9387   \n",
       "568                 268.6        0.08996      0.06444          0.0000   \n",
       "\n",
       "     Mean_fractal_dimension  SE_fractal_dimension  Worst_fractal_dimension  \n",
       "0                    0.2654                0.4601                  0.11890  \n",
       "1                    0.1860                0.2750                  0.08902  \n",
       "2                    0.2430                0.3613                  0.08758  \n",
       "3                    0.2575                0.6638                  0.17300  \n",
       "4                    0.1625                0.2364                  0.07678  \n",
       "..                      ...                   ...                      ...  \n",
       "564                  0.2216                0.2060                  0.07115  \n",
       "565                  0.1628                0.2572                  0.06637  \n",
       "566                  0.1418                0.2218                  0.07820  \n",
       "567                  0.2650                0.4087                  0.12400  \n",
       "568                  0.0000                0.2871                  0.07039  \n",
       "\n",
       "[569 rows x 31 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dia_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d913fcaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data = dia_data['Diagnosis']\n",
    "X_data = dia_data.drop(labels=['Diagnosis'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1477f600",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.2, random_state=24,stratify=y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "023c8dc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "B    0.626374\n",
       "M    0.373626\n",
       "Name: Diagnosis, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()/len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d453516",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "B    0.631579\n",
       "M    0.368421\n",
       "Name: Diagnosis, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()/len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8cd98e23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean_radius</th>\n",
       "      <th>SE_radius</th>\n",
       "      <th>Worst_radius</th>\n",
       "      <th>Mean_texture</th>\n",
       "      <th>SE_texture</th>\n",
       "      <th>Worst_texture</th>\n",
       "      <th>Mean_perimeter</th>\n",
       "      <th>SE_perimeter</th>\n",
       "      <th>Worst_perimeter</th>\n",
       "      <th>Mean_area</th>\n",
       "      <th>...</th>\n",
       "      <th>Worst_concavity</th>\n",
       "      <th>Mean_concave_points</th>\n",
       "      <th>SE_concave_points</th>\n",
       "      <th>Worst_concave_points</th>\n",
       "      <th>Mean_symmetry</th>\n",
       "      <th>SE_symmetry</th>\n",
       "      <th>Worst_symmetry</th>\n",
       "      <th>Mean_fractal_dimension</th>\n",
       "      <th>SE_fractal_dimension</th>\n",
       "      <th>Worst_fractal_dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.336157</td>\n",
       "      <td>-1.410560</td>\n",
       "      <td>0.266116</td>\n",
       "      <td>0.199219</td>\n",
       "      <td>-1.256387</td>\n",
       "      <td>-0.653471</td>\n",
       "      <td>-0.684988</td>\n",
       "      <td>-0.573002</td>\n",
       "      <td>-0.331334</td>\n",
       "      <td>-1.055168</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005061</td>\n",
       "      <td>-1.599705</td>\n",
       "      <td>-0.065354</td>\n",
       "      <td>-0.090822</td>\n",
       "      <td>-0.881460</td>\n",
       "      <td>-0.504742</td>\n",
       "      <td>-0.648909</td>\n",
       "      <td>-0.492863</td>\n",
       "      <td>-0.658605</td>\n",
       "      <td>-0.898027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.122500</td>\n",
       "      <td>-0.423797</td>\n",
       "      <td>-1.116974</td>\n",
       "      <td>-0.964942</td>\n",
       "      <td>-1.188528</td>\n",
       "      <td>-0.845806</td>\n",
       "      <td>-0.388103</td>\n",
       "      <td>-0.988817</td>\n",
       "      <td>0.549883</td>\n",
       "      <td>0.029735</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.985900</td>\n",
       "      <td>-0.210767</td>\n",
       "      <td>-0.941722</td>\n",
       "      <td>-0.846207</td>\n",
       "      <td>-1.642711</td>\n",
       "      <td>-0.714484</td>\n",
       "      <td>-0.385620</td>\n",
       "      <td>-1.191802</td>\n",
       "      <td>-0.060232</td>\n",
       "      <td>-0.330165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.686658</td>\n",
       "      <td>0.655402</td>\n",
       "      <td>1.638599</td>\n",
       "      <td>1.833097</td>\n",
       "      <td>0.136585</td>\n",
       "      <td>-0.028713</td>\n",
       "      <td>0.736095</td>\n",
       "      <td>1.220561</td>\n",
       "      <td>-0.835406</td>\n",
       "      <td>-1.264832</td>\n",
       "      <td>...</td>\n",
       "      <td>2.339697</td>\n",
       "      <td>0.807895</td>\n",
       "      <td>2.413172</td>\n",
       "      <td>2.780332</td>\n",
       "      <td>0.814112</td>\n",
       "      <td>0.366922</td>\n",
       "      <td>1.226383</td>\n",
       "      <td>1.889326</td>\n",
       "      <td>-0.217285</td>\n",
       "      <td>-0.435788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.076009</td>\n",
       "      <td>-0.814343</td>\n",
       "      <td>-0.127598</td>\n",
       "      <td>-0.176019</td>\n",
       "      <td>-0.619557</td>\n",
       "      <td>-0.693923</td>\n",
       "      <td>-0.976511</td>\n",
       "      <td>-1.009083</td>\n",
       "      <td>-1.477280</td>\n",
       "      <td>-0.627398</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.190192</td>\n",
       "      <td>-1.318422</td>\n",
       "      <td>-0.264118</td>\n",
       "      <td>-0.295398</td>\n",
       "      <td>-1.118665</td>\n",
       "      <td>-0.915589</td>\n",
       "      <td>-1.121379</td>\n",
       "      <td>-1.231095</td>\n",
       "      <td>-1.644898</td>\n",
       "      <td>-0.874071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.412172</td>\n",
       "      <td>0.334184</td>\n",
       "      <td>-0.391488</td>\n",
       "      <td>-0.490456</td>\n",
       "      <td>0.212646</td>\n",
       "      <td>0.312133</td>\n",
       "      <td>0.219882</td>\n",
       "      <td>0.308966</td>\n",
       "      <td>-0.280565</td>\n",
       "      <td>1.092125</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.597494</td>\n",
       "      <td>-0.051849</td>\n",
       "      <td>-0.532148</td>\n",
       "      <td>-0.621265</td>\n",
       "      <td>-0.174240</td>\n",
       "      <td>-0.188278</td>\n",
       "      <td>-0.249532</td>\n",
       "      <td>-0.057145</td>\n",
       "      <td>-1.068513</td>\n",
       "      <td>0.038429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>1.794815</td>\n",
       "      <td>0.052252</td>\n",
       "      <td>1.799818</td>\n",
       "      <td>1.803293</td>\n",
       "      <td>1.254392</td>\n",
       "      <td>0.836510</td>\n",
       "      <td>1.551562</td>\n",
       "      <td>2.031217</td>\n",
       "      <td>-0.320455</td>\n",
       "      <td>-0.338935</td>\n",
       "      <td>...</td>\n",
       "      <td>1.229065</td>\n",
       "      <td>-0.115416</td>\n",
       "      <td>1.184449</td>\n",
       "      <td>1.109174</td>\n",
       "      <td>1.486192</td>\n",
       "      <td>0.238609</td>\n",
       "      <td>1.196453</td>\n",
       "      <td>1.563144</td>\n",
       "      <td>0.197335</td>\n",
       "      <td>-0.185341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>-0.087701</td>\n",
       "      <td>-0.324428</td>\n",
       "      <td>-0.138205</td>\n",
       "      <td>-0.178701</td>\n",
       "      <td>-1.270555</td>\n",
       "      <td>-0.757972</td>\n",
       "      <td>-0.748829</td>\n",
       "      <td>-0.921175</td>\n",
       "      <td>-1.230684</td>\n",
       "      <td>-1.004511</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.175495</td>\n",
       "      <td>-0.530191</td>\n",
       "      <td>-0.285500</td>\n",
       "      <td>-0.260302</td>\n",
       "      <td>-1.561886</td>\n",
       "      <td>-0.451072</td>\n",
       "      <td>-0.554443</td>\n",
       "      <td>-0.820410</td>\n",
       "      <td>-0.873767</td>\n",
       "      <td>-0.763003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>-0.613870</td>\n",
       "      <td>-0.248167</td>\n",
       "      <td>-0.664712</td>\n",
       "      <td>-0.618019</td>\n",
       "      <td>-1.034168</td>\n",
       "      <td>-1.062299</td>\n",
       "      <td>-0.862171</td>\n",
       "      <td>-0.915931</td>\n",
       "      <td>0.201748</td>\n",
       "      <td>-0.258728</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.645782</td>\n",
       "      <td>-0.709767</td>\n",
       "      <td>-0.692665</td>\n",
       "      <td>-0.621628</td>\n",
       "      <td>-0.802392</td>\n",
       "      <td>-1.026876</td>\n",
       "      <td>-0.855471</td>\n",
       "      <td>-0.778385</td>\n",
       "      <td>-0.190586</td>\n",
       "      <td>-0.548489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>4.112882</td>\n",
       "      <td>-0.195016</td>\n",
       "      <td>4.120524</td>\n",
       "      <td>5.525866</td>\n",
       "      <td>1.321506</td>\n",
       "      <td>0.887075</td>\n",
       "      <td>2.883243</td>\n",
       "      <td>2.912136</td>\n",
       "      <td>-0.596062</td>\n",
       "      <td>-1.081904</td>\n",
       "      <td>...</td>\n",
       "      <td>2.505557</td>\n",
       "      <td>-1.164272</td>\n",
       "      <td>2.464368</td>\n",
       "      <td>2.963995</td>\n",
       "      <td>-0.811178</td>\n",
       "      <td>-0.641074</td>\n",
       "      <td>0.211107</td>\n",
       "      <td>0.686246</td>\n",
       "      <td>-1.976280</td>\n",
       "      <td>-1.573690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>0.298156</td>\n",
       "      <td>0.119269</td>\n",
       "      <td>0.378545</td>\n",
       "      <td>0.180740</td>\n",
       "      <td>0.553432</td>\n",
       "      <td>0.956368</td>\n",
       "      <td>1.011658</td>\n",
       "      <td>1.041493</td>\n",
       "      <td>0.154605</td>\n",
       "      <td>-0.013886</td>\n",
       "      <td>...</td>\n",
       "      <td>0.431258</td>\n",
       "      <td>-0.248907</td>\n",
       "      <td>0.506845</td>\n",
       "      <td>0.283597</td>\n",
       "      <td>0.985427</td>\n",
       "      <td>1.016505</td>\n",
       "      <td>1.147350</td>\n",
       "      <td>1.475151</td>\n",
       "      <td>-0.113630</td>\n",
       "      <td>-0.098773</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>455 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Mean_radius  SE_radius  Worst_radius  Mean_texture  SE_texture  \\\n",
       "0       0.336157  -1.410560      0.266116      0.199219   -1.256387   \n",
       "1      -1.122500  -0.423797     -1.116974     -0.964942   -1.188528   \n",
       "2       1.686658   0.655402      1.638599      1.833097    0.136585   \n",
       "3      -0.076009  -0.814343     -0.127598     -0.176019   -0.619557   \n",
       "4      -0.412172   0.334184     -0.391488     -0.490456    0.212646   \n",
       "..           ...        ...           ...           ...         ...   \n",
       "450     1.794815   0.052252      1.799818      1.803293    1.254392   \n",
       "451    -0.087701  -0.324428     -0.138205     -0.178701   -1.270555   \n",
       "452    -0.613870  -0.248167     -0.664712     -0.618019   -1.034168   \n",
       "453     4.112882  -0.195016      4.120524      5.525866    1.321506   \n",
       "454     0.298156   0.119269      0.378545      0.180740    0.553432   \n",
       "\n",
       "     Worst_texture  Mean_perimeter  SE_perimeter  Worst_perimeter  Mean_area  \\\n",
       "0        -0.653471       -0.684988     -0.573002        -0.331334  -1.055168   \n",
       "1        -0.845806       -0.388103     -0.988817         0.549883   0.029735   \n",
       "2        -0.028713        0.736095      1.220561        -0.835406  -1.264832   \n",
       "3        -0.693923       -0.976511     -1.009083        -1.477280  -0.627398   \n",
       "4         0.312133        0.219882      0.308966        -0.280565   1.092125   \n",
       "..             ...             ...           ...              ...        ...   \n",
       "450       0.836510        1.551562      2.031217        -0.320455  -0.338935   \n",
       "451      -0.757972       -0.748829     -0.921175        -1.230684  -1.004511   \n",
       "452      -1.062299       -0.862171     -0.915931         0.201748  -0.258728   \n",
       "453       0.887075        2.883243      2.912136        -0.596062  -1.081904   \n",
       "454       0.956368        1.011658      1.041493         0.154605  -0.013886   \n",
       "\n",
       "     ...  Worst_concavity  Mean_concave_points  SE_concave_points  \\\n",
       "0    ...         0.005061            -1.599705          -0.065354   \n",
       "1    ...        -0.985900            -0.210767          -0.941722   \n",
       "2    ...         2.339697             0.807895           2.413172   \n",
       "3    ...        -0.190192            -1.318422          -0.264118   \n",
       "4    ...        -0.597494            -0.051849          -0.532148   \n",
       "..   ...              ...                  ...                ...   \n",
       "450  ...         1.229065            -0.115416           1.184449   \n",
       "451  ...        -0.175495            -0.530191          -0.285500   \n",
       "452  ...        -0.645782            -0.709767          -0.692665   \n",
       "453  ...         2.505557            -1.164272           2.464368   \n",
       "454  ...         0.431258            -0.248907           0.506845   \n",
       "\n",
       "     Worst_concave_points  Mean_symmetry  SE_symmetry  Worst_symmetry  \\\n",
       "0               -0.090822      -0.881460    -0.504742       -0.648909   \n",
       "1               -0.846207      -1.642711    -0.714484       -0.385620   \n",
       "2                2.780332       0.814112     0.366922        1.226383   \n",
       "3               -0.295398      -1.118665    -0.915589       -1.121379   \n",
       "4               -0.621265      -0.174240    -0.188278       -0.249532   \n",
       "..                    ...            ...          ...             ...   \n",
       "450              1.109174       1.486192     0.238609        1.196453   \n",
       "451             -0.260302      -1.561886    -0.451072       -0.554443   \n",
       "452             -0.621628      -0.802392    -1.026876       -0.855471   \n",
       "453              2.963995      -0.811178    -0.641074        0.211107   \n",
       "454              0.283597       0.985427     1.016505        1.147350   \n",
       "\n",
       "     Mean_fractal_dimension  SE_fractal_dimension  Worst_fractal_dimension  \n",
       "0                 -0.492863             -0.658605                -0.898027  \n",
       "1                 -1.191802             -0.060232                -0.330165  \n",
       "2                  1.889326             -0.217285                -0.435788  \n",
       "3                 -1.231095             -1.644898                -0.874071  \n",
       "4                 -0.057145             -1.068513                 0.038429  \n",
       "..                      ...                   ...                      ...  \n",
       "450                1.563144              0.197335                -0.185341  \n",
       "451               -0.820410             -0.873767                -0.763003  \n",
       "452               -0.778385             -0.190586                -0.548489  \n",
       "453                0.686246             -1.976280                -1.573690  \n",
       "454                1.475151             -0.113630                -0.098773  \n",
       "\n",
       "[455 rows x 30 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_norm = scaler.fit_transform(X_train)\n",
    "X_test_norm = scaler.transform(X_test)\n",
    "X_train_norm_df = pd.DataFrame(X_train_norm, columns=X_train.columns)\n",
    "X_test_norm_df = pd.DataFrame(X_test_norm, columns=X_test.columns)\n",
    "X_train_norm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2d99ec05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ran_num = [random.randrange(1, 500000000, 1) for i in range(30)]\n",
    "len(Ran_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "01cc16c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train_acc_arr = []\n",
    "test_acc_arr = []\n",
    "train_prec_arr = []\n",
    "test_prec_arr = []\n",
    "train_rec_arr = []\n",
    "test_rec_arr = []\n",
    "train_f1_arr = []\n",
    "test_f1_arr = []\n",
    "train_auc_arr = []\n",
    "test_auc_arr = []\n",
    "for i in Ran_num:\n",
    "    l1_svc = LinearSVC(penalty='l1',loss='squared_hinge',dual=False ,random_state=i)\n",
    "    test_params = {'C':[0.03,0.032,0.033,0.034,0.035]}\n",
    "\n",
    "    l1_svc_gs = GridSearchCV(estimator = l1_svc, param_grid = test_params,cv=5).\\\n",
    "    fit(X_train_norm_df,y_train)\n",
    "    \n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit(y_train)\n",
    "    \n",
    "    pred_l1_gs_train = l1_svc_gs.predict(X_train_norm_df)\n",
    "    pred_l1_gs_test = l1_svc_gs.predict(X_test_norm_df)\n",
    "    train_acc = accuracy_score(y_train,pred_l1_gs_train)\n",
    "    train_acc_arr.append(train_acc)\n",
    "    test_acc = accuracy_score(y_test,pred_l1_gs_test)\n",
    "    test_acc_arr.append(test_acc)\n",
    "    train_prec = precision_score(y_train,pred_l1_gs_train,average='micro')\n",
    "    train_prec_arr.append(train_prec)\n",
    "    test_prec = precision_score(y_test,pred_l1_gs_test,average='micro')\n",
    "    test_prec_arr.append(test_prec)\n",
    "    train_rec = recall_score(y_train,pred_l1_gs_train,average='micro')\n",
    "    train_rec_arr.append(train_rec)\n",
    "    test_rec = recall_score(y_test,pred_l1_gs_test,average='micro')\n",
    "    test_rec_arr.append(test_rec)\n",
    "    train_f1 = f1_score(y_train,pred_l1_gs_train,average='micro')\n",
    "    train_f1_arr.append(train_f1)\n",
    "    test_f1 = f1_score(y_test,pred_l1_gs_test,average='micro')\n",
    "    test_f1_arr.append(test_f1)\n",
    "    train_auc = roc_auc_score(y_train,le.transform(pred_l1_gs_train))\n",
    "    train_auc_arr.append(train_auc)\n",
    "    test_auc = roc_auc_score(y_test,le.transform(pred_l1_gs_test))\n",
    "    test_auc_arr.append(test_auc)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0a431890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train scores: \n",
      "Accuracy: 0.9824175824175824\n",
      "Precision: 0.9824175824175824\n",
      "Recall: 0.9824175824175824\n",
      "F1: 0.9824175824175824\n",
      "AUC: 0.9776573787409705\n",
      "Test scores: \n",
      "Accuracy: 0.9736842105263156\n",
      "Precision: 0.9736842105263156\n",
      "Recall: 0.9736842105263156\n",
      "F1: 0.9736842105263156\n",
      "AUC: 0.9692460317460317\n"
     ]
    }
   ],
   "source": [
    "print('Train scores: ')\n",
    "print('Accuracy: '+str(np.average(train_acc_arr)))\n",
    "print('Precision: '+str(np.average(train_prec_arr)))\n",
    "print('Recall: '+str(np.average(train_rec_arr)))\n",
    "print('F1: '+str(np.average(train_f1_arr)))\n",
    "print('AUC: '+str(np.average(train_auc_arr)))\n",
    "\n",
    "print('Test scores: ')\n",
    "print('Accuracy: '+str(np.average(test_acc_arr)))\n",
    "print('Precision: '+str(np.average(test_prec_arr)))\n",
    "print('Recall: '+str(np.average(test_rec_arr)))\n",
    "print('F1: '+str(np.average(test_f1_arr)))\n",
    "print('AUC: '+str(np.average(test_auc_arr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "828c184b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function plot_roc_curve is deprecated; Function :func:`plot_roc_curve` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: :meth:`sklearn.metric.RocCurveDisplay.from_predictions` or :meth:`sklearn.metric.RocCurveDisplay.from_estimator`.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_roc_curve(l1_svc_gs, X_train_norm_df, y_train) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bad41ce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function plot_roc_curve is deprecated; Function :func:`plot_roc_curve` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: :meth:`sklearn.metric.RocCurveDisplay.from_predictions` or :meth:`sklearn.metric.RocCurveDisplay.from_estimator`.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_roc_curve(l1_svc_gs, X_test_norm_df, y_test) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f6271b62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train condfusion matrix: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[284,   1],\n",
       "       [  7, 163]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('train condfusion matrix: ')\n",
    "confusion_matrix(y_train, pred_l1_gs_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bc70a35a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test condfusion matrix: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[71,  1],\n",
       "       [ 2, 40]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('test condfusion matrix: ')\n",
    "confusion_matrix(y_test, pred_l1_gs_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94914a3",
   "metadata": {},
   "source": [
    "#### ii. Semi-Supervised Learning/ Self-training: select 50% of the positive class along with 50% of the negative class in the training set as labeled data and the rest as unlabelled data. You can select them randomly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c827f0d",
   "metadata": {},
   "source": [
    "##### A. Train an L1-penalized SVM to classify the labeled data Use normalized data. Choose the penalty parameter using 5 fold cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c35ff624",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1    0.503297\n",
       "B     0.305495\n",
       "M     0.191209\n",
       "Name: Diagnosis, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rng = np.random.RandomState(24)\n",
    "random_unlabeled_points = rng.rand(y_train.shape[0]) < 0.5\n",
    "y_train[random_unlabeled_points] = -1\n",
    "y_train.value_counts()/len(y_train)\n",
    "# source: https://scikit-learn.org/stable/modules/generated/sklearn.semi_supervised.SelfTrainingClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ff92c0d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean_radius</th>\n",
       "      <th>SE_radius</th>\n",
       "      <th>Worst_radius</th>\n",
       "      <th>Mean_texture</th>\n",
       "      <th>SE_texture</th>\n",
       "      <th>Worst_texture</th>\n",
       "      <th>Mean_perimeter</th>\n",
       "      <th>SE_perimeter</th>\n",
       "      <th>Worst_perimeter</th>\n",
       "      <th>Mean_area</th>\n",
       "      <th>...</th>\n",
       "      <th>Worst_concavity</th>\n",
       "      <th>Mean_concave_points</th>\n",
       "      <th>SE_concave_points</th>\n",
       "      <th>Worst_concave_points</th>\n",
       "      <th>Mean_symmetry</th>\n",
       "      <th>SE_symmetry</th>\n",
       "      <th>Worst_symmetry</th>\n",
       "      <th>Mean_fractal_dimension</th>\n",
       "      <th>SE_fractal_dimension</th>\n",
       "      <th>Worst_fractal_dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.336157</td>\n",
       "      <td>-1.410560</td>\n",
       "      <td>0.266116</td>\n",
       "      <td>0.199219</td>\n",
       "      <td>-1.256387</td>\n",
       "      <td>-0.653471</td>\n",
       "      <td>-0.684988</td>\n",
       "      <td>-0.573002</td>\n",
       "      <td>-0.331334</td>\n",
       "      <td>-1.055168</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005061</td>\n",
       "      <td>-1.599705</td>\n",
       "      <td>-0.065354</td>\n",
       "      <td>-0.090822</td>\n",
       "      <td>-0.881460</td>\n",
       "      <td>-0.504742</td>\n",
       "      <td>-0.648909</td>\n",
       "      <td>-0.492863</td>\n",
       "      <td>-0.658605</td>\n",
       "      <td>-0.898027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.122500</td>\n",
       "      <td>-0.423797</td>\n",
       "      <td>-1.116974</td>\n",
       "      <td>-0.964942</td>\n",
       "      <td>-1.188528</td>\n",
       "      <td>-0.845806</td>\n",
       "      <td>-0.388103</td>\n",
       "      <td>-0.988817</td>\n",
       "      <td>0.549883</td>\n",
       "      <td>0.029735</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.985900</td>\n",
       "      <td>-0.210767</td>\n",
       "      <td>-0.941722</td>\n",
       "      <td>-0.846207</td>\n",
       "      <td>-1.642711</td>\n",
       "      <td>-0.714484</td>\n",
       "      <td>-0.385620</td>\n",
       "      <td>-1.191802</td>\n",
       "      <td>-0.060232</td>\n",
       "      <td>-0.330165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.686658</td>\n",
       "      <td>0.655402</td>\n",
       "      <td>1.638599</td>\n",
       "      <td>1.833097</td>\n",
       "      <td>0.136585</td>\n",
       "      <td>-0.028713</td>\n",
       "      <td>0.736095</td>\n",
       "      <td>1.220561</td>\n",
       "      <td>-0.835406</td>\n",
       "      <td>-1.264832</td>\n",
       "      <td>...</td>\n",
       "      <td>2.339697</td>\n",
       "      <td>0.807895</td>\n",
       "      <td>2.413172</td>\n",
       "      <td>2.780332</td>\n",
       "      <td>0.814112</td>\n",
       "      <td>0.366922</td>\n",
       "      <td>1.226383</td>\n",
       "      <td>1.889326</td>\n",
       "      <td>-0.217285</td>\n",
       "      <td>-0.435788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.067239</td>\n",
       "      <td>1.025149</td>\n",
       "      <td>0.007741</td>\n",
       "      <td>-0.140552</td>\n",
       "      <td>2.671227</td>\n",
       "      <td>1.359015</td>\n",
       "      <td>0.834600</td>\n",
       "      <td>1.136140</td>\n",
       "      <td>1.590664</td>\n",
       "      <td>1.586031</td>\n",
       "      <td>...</td>\n",
       "      <td>0.634909</td>\n",
       "      <td>2.551220</td>\n",
       "      <td>0.657424</td>\n",
       "      <td>0.516359</td>\n",
       "      <td>3.950483</td>\n",
       "      <td>1.637095</td>\n",
       "      <td>0.886867</td>\n",
       "      <td>1.320404</td>\n",
       "      <td>2.396077</td>\n",
       "      <td>1.330955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.315708</td>\n",
       "      <td>-0.236613</td>\n",
       "      <td>-0.305363</td>\n",
       "      <td>-0.356932</td>\n",
       "      <td>-1.712757</td>\n",
       "      <td>-0.472748</td>\n",
       "      <td>-0.602194</td>\n",
       "      <td>-0.775928</td>\n",
       "      <td>0.223506</td>\n",
       "      <td>-0.555634</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.429534</td>\n",
       "      <td>-0.188518</td>\n",
       "      <td>-0.312002</td>\n",
       "      <td>-0.449421</td>\n",
       "      <td>-1.729686</td>\n",
       "      <td>-0.146329</td>\n",
       "      <td>-0.535737</td>\n",
       "      <td>-0.731051</td>\n",
       "      <td>0.472177</td>\n",
       "      <td>-0.636146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>0.189999</td>\n",
       "      <td>-1.232619</td>\n",
       "      <td>0.290299</td>\n",
       "      <td>0.033208</td>\n",
       "      <td>0.493776</td>\n",
       "      <td>1.486364</td>\n",
       "      <td>0.699935</td>\n",
       "      <td>0.382114</td>\n",
       "      <td>0.992306</td>\n",
       "      <td>1.564924</td>\n",
       "      <td>...</td>\n",
       "      <td>0.059648</td>\n",
       "      <td>-1.184931</td>\n",
       "      <td>0.223757</td>\n",
       "      <td>-0.108825</td>\n",
       "      <td>-0.064423</td>\n",
       "      <td>0.666112</td>\n",
       "      <td>0.219524</td>\n",
       "      <td>-0.052593</td>\n",
       "      <td>-0.124624</td>\n",
       "      <td>0.431522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>-0.280630</td>\n",
       "      <td>-0.832830</td>\n",
       "      <td>-0.243845</td>\n",
       "      <td>-0.372430</td>\n",
       "      <td>0.821885</td>\n",
       "      <td>0.426372</td>\n",
       "      <td>-0.538478</td>\n",
       "      <td>-0.454235</td>\n",
       "      <td>0.560763</td>\n",
       "      <td>0.727676</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.351853</td>\n",
       "      <td>-0.843258</td>\n",
       "      <td>-0.318627</td>\n",
       "      <td>-0.433782</td>\n",
       "      <td>-0.064423</td>\n",
       "      <td>0.136205</td>\n",
       "      <td>-0.401988</td>\n",
       "      <td>-0.628645</td>\n",
       "      <td>0.436055</td>\n",
       "      <td>-0.126540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>-0.087701</td>\n",
       "      <td>-0.324428</td>\n",
       "      <td>-0.138205</td>\n",
       "      <td>-0.178701</td>\n",
       "      <td>-1.270555</td>\n",
       "      <td>-0.757972</td>\n",
       "      <td>-0.748829</td>\n",
       "      <td>-0.921175</td>\n",
       "      <td>-1.230684</td>\n",
       "      <td>-1.004511</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.175495</td>\n",
       "      <td>-0.530191</td>\n",
       "      <td>-0.285500</td>\n",
       "      <td>-0.260302</td>\n",
       "      <td>-1.561886</td>\n",
       "      <td>-0.451072</td>\n",
       "      <td>-0.554443</td>\n",
       "      <td>-0.820410</td>\n",
       "      <td>-0.873767</td>\n",
       "      <td>-0.763003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>4.112882</td>\n",
       "      <td>-0.195016</td>\n",
       "      <td>4.120524</td>\n",
       "      <td>5.525866</td>\n",
       "      <td>1.321506</td>\n",
       "      <td>0.887075</td>\n",
       "      <td>2.883243</td>\n",
       "      <td>2.912136</td>\n",
       "      <td>-0.596062</td>\n",
       "      <td>-1.081904</td>\n",
       "      <td>...</td>\n",
       "      <td>2.505557</td>\n",
       "      <td>-1.164272</td>\n",
       "      <td>2.464368</td>\n",
       "      <td>2.963995</td>\n",
       "      <td>-0.811178</td>\n",
       "      <td>-0.641074</td>\n",
       "      <td>0.211107</td>\n",
       "      <td>0.686246</td>\n",
       "      <td>-1.976280</td>\n",
       "      <td>-1.573690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>0.298156</td>\n",
       "      <td>0.119269</td>\n",
       "      <td>0.378545</td>\n",
       "      <td>0.180740</td>\n",
       "      <td>0.553432</td>\n",
       "      <td>0.956368</td>\n",
       "      <td>1.011658</td>\n",
       "      <td>1.041493</td>\n",
       "      <td>0.154605</td>\n",
       "      <td>-0.013886</td>\n",
       "      <td>...</td>\n",
       "      <td>0.431258</td>\n",
       "      <td>-0.248907</td>\n",
       "      <td>0.506845</td>\n",
       "      <td>0.283597</td>\n",
       "      <td>0.985427</td>\n",
       "      <td>1.016505</td>\n",
       "      <td>1.147350</td>\n",
       "      <td>1.475151</td>\n",
       "      <td>-0.113630</td>\n",
       "      <td>-0.098773</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>226 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Mean_radius  SE_radius  Worst_radius  Mean_texture  SE_texture  \\\n",
       "0       0.336157  -1.410560      0.266116      0.199219   -1.256387   \n",
       "1      -1.122500  -0.423797     -1.116974     -0.964942   -1.188528   \n",
       "2       1.686658   0.655402      1.638599      1.833097    0.136585   \n",
       "5      -0.067239   1.025149      0.007741     -0.140552    2.671227   \n",
       "6      -0.315708  -0.236613     -0.305363     -0.356932   -1.712757   \n",
       "..           ...        ...           ...           ...         ...   \n",
       "444     0.189999  -1.232619      0.290299      0.033208    0.493776   \n",
       "447    -0.280630  -0.832830     -0.243845     -0.372430    0.821885   \n",
       "451    -0.087701  -0.324428     -0.138205     -0.178701   -1.270555   \n",
       "453     4.112882  -0.195016      4.120524      5.525866    1.321506   \n",
       "454     0.298156   0.119269      0.378545      0.180740    0.553432   \n",
       "\n",
       "     Worst_texture  Mean_perimeter  SE_perimeter  Worst_perimeter  Mean_area  \\\n",
       "0        -0.653471       -0.684988     -0.573002        -0.331334  -1.055168   \n",
       "1        -0.845806       -0.388103     -0.988817         0.549883   0.029735   \n",
       "2        -0.028713        0.736095      1.220561        -0.835406  -1.264832   \n",
       "5         1.359015        0.834600      1.136140         1.590664   1.586031   \n",
       "6        -0.472748       -0.602194     -0.775928         0.223506  -0.555634   \n",
       "..             ...             ...           ...              ...        ...   \n",
       "444       1.486364        0.699935      0.382114         0.992306   1.564924   \n",
       "447       0.426372       -0.538478     -0.454235         0.560763   0.727676   \n",
       "451      -0.757972       -0.748829     -0.921175        -1.230684  -1.004511   \n",
       "453       0.887075        2.883243      2.912136        -0.596062  -1.081904   \n",
       "454       0.956368        1.011658      1.041493         0.154605  -0.013886   \n",
       "\n",
       "     ...  Worst_concavity  Mean_concave_points  SE_concave_points  \\\n",
       "0    ...         0.005061            -1.599705          -0.065354   \n",
       "1    ...        -0.985900            -0.210767          -0.941722   \n",
       "2    ...         2.339697             0.807895           2.413172   \n",
       "5    ...         0.634909             2.551220           0.657424   \n",
       "6    ...        -0.429534            -0.188518          -0.312002   \n",
       "..   ...              ...                  ...                ...   \n",
       "444  ...         0.059648            -1.184931           0.223757   \n",
       "447  ...        -0.351853            -0.843258          -0.318627   \n",
       "451  ...        -0.175495            -0.530191          -0.285500   \n",
       "453  ...         2.505557            -1.164272           2.464368   \n",
       "454  ...         0.431258            -0.248907           0.506845   \n",
       "\n",
       "     Worst_concave_points  Mean_symmetry  SE_symmetry  Worst_symmetry  \\\n",
       "0               -0.090822      -0.881460    -0.504742       -0.648909   \n",
       "1               -0.846207      -1.642711    -0.714484       -0.385620   \n",
       "2                2.780332       0.814112     0.366922        1.226383   \n",
       "5                0.516359       3.950483     1.637095        0.886867   \n",
       "6               -0.449421      -1.729686    -0.146329       -0.535737   \n",
       "..                    ...            ...          ...             ...   \n",
       "444             -0.108825      -0.064423     0.666112        0.219524   \n",
       "447             -0.433782      -0.064423     0.136205       -0.401988   \n",
       "451             -0.260302      -1.561886    -0.451072       -0.554443   \n",
       "453              2.963995      -0.811178    -0.641074        0.211107   \n",
       "454              0.283597       0.985427     1.016505        1.147350   \n",
       "\n",
       "     Mean_fractal_dimension  SE_fractal_dimension  Worst_fractal_dimension  \n",
       "0                 -0.492863             -0.658605                -0.898027  \n",
       "1                 -1.191802             -0.060232                -0.330165  \n",
       "2                  1.889326             -0.217285                -0.435788  \n",
       "5                  1.320404              2.396077                 1.330955  \n",
       "6                 -0.731051              0.472177                -0.636146  \n",
       "..                      ...                   ...                      ...  \n",
       "444               -0.052593             -0.124624                 0.431522  \n",
       "447               -0.628645              0.436055                -0.126540  \n",
       "451               -0.820410             -0.873767                -0.763003  \n",
       "453                0.686246             -1.976280                -1.573690  \n",
       "454                1.475151             -0.113630                -0.098773  \n",
       "\n",
       "[226 rows x 30 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_norm_df_labeled = X_train_norm_df.drop(index=X_train_norm_df[random_unlabeled_points].index)\n",
    "y_train_labeled = y_train.drop(index=y_train[random_unlabeled_points].index)\n",
    "X_train_norm_df_labeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7f4a48bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC(C=0.06, dual=False, penalty='l1', random_state=8443008)\n",
      "LinearSVC(C=0.06, dual=False, penalty='l1', random_state=160390951)\n",
      "LinearSVC(C=0.06, dual=False, penalty='l1', random_state=311869477)\n",
      "LinearSVC(C=0.06, dual=False, penalty='l1', random_state=496547442)\n",
      "LinearSVC(C=0.06, dual=False, penalty='l1', random_state=180870768)\n",
      "LinearSVC(C=0.06, dual=False, penalty='l1', random_state=445336289)\n",
      "LinearSVC(C=0.06, dual=False, penalty='l1', random_state=318275370)\n",
      "LinearSVC(C=0.06, dual=False, penalty='l1', random_state=342505757)\n",
      "LinearSVC(C=0.06, dual=False, penalty='l1', random_state=439587497)\n",
      "LinearSVC(C=0.06, dual=False, penalty='l1', random_state=185726978)\n",
      "LinearSVC(C=0.06, dual=False, penalty='l1', random_state=52799365)\n",
      "LinearSVC(C=0.06, dual=False, penalty='l1', random_state=124454811)\n",
      "LinearSVC(C=0.06, dual=False, penalty='l1', random_state=355632828)\n",
      "LinearSVC(C=0.06, dual=False, penalty='l1', random_state=388845676)\n",
      "LinearSVC(C=0.06, dual=False, penalty='l1', random_state=328821602)\n",
      "LinearSVC(C=0.06, dual=False, penalty='l1', random_state=25624756)\n",
      "LinearSVC(C=0.06, dual=False, penalty='l1', random_state=130277815)\n",
      "LinearSVC(C=0.06, dual=False, penalty='l1', random_state=327415432)\n",
      "LinearSVC(C=0.06, dual=False, penalty='l1', random_state=421996527)\n",
      "LinearSVC(C=0.06, dual=False, penalty='l1', random_state=18625538)\n",
      "LinearSVC(C=0.06, dual=False, penalty='l1', random_state=218492950)\n",
      "LinearSVC(C=0.06, dual=False, penalty='l1', random_state=97068615)\n",
      "LinearSVC(C=0.06, dual=False, penalty='l1', random_state=93114985)\n",
      "LinearSVC(C=0.06, dual=False, penalty='l1', random_state=375666491)\n",
      "LinearSVC(C=0.06, dual=False, penalty='l1', random_state=91697285)\n",
      "LinearSVC(C=0.06, dual=False, penalty='l1', random_state=342903215)\n",
      "LinearSVC(C=0.06, dual=False, penalty='l1', random_state=85001814)\n",
      "LinearSVC(C=0.06, dual=False, penalty='l1', random_state=286377195)\n",
      "LinearSVC(C=0.06, dual=False, penalty='l1', random_state=279798626)\n",
      "LinearSVC(C=0.06, dual=False, penalty='l1', random_state=132396086)\n"
     ]
    }
   ],
   "source": [
    "train_acc_arr = []\n",
    "test_acc_arr = []\n",
    "train_prec_arr = []\n",
    "test_prec_arr = []\n",
    "train_rec_arr = []\n",
    "test_rec_arr = []\n",
    "train_f1_arr = []\n",
    "test_f1_arr = []\n",
    "train_auc_arr = []\n",
    "test_auc_arr = []\n",
    "for i in Ran_num:\n",
    "    l1_svc = LinearSVC(penalty='l1',loss='squared_hinge',dual=False ,random_state=i)\n",
    "    test_params = {'C':[0.02,0.03,0.04, 0.05,0.06,0.07,0.1]}\n",
    "\n",
    "    l1_svc_gs = GridSearchCV(estimator = l1_svc, param_grid = test_params,cv=5).\\\n",
    "    fit(X_train_norm_df_labeled,y_train_labeled)\n",
    "    print(l1_svc_gs.best_estimator_)\n",
    "    \n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit(y_train_labeled)\n",
    "    \n",
    "    pred_l1_gs_train = l1_svc_gs.predict(X_train_norm_df_labeled)\n",
    "    pred_l1_gs_test = l1_svc_gs.predict(X_test_norm_df)\n",
    "    train_acc = accuracy_score(y_train_labeled,pred_l1_gs_train)\n",
    "    train_acc_arr.append(train_acc)\n",
    "    test_acc = accuracy_score(y_test,pred_l1_gs_test)\n",
    "    test_acc_arr.append(test_acc)\n",
    "    train_prec = precision_score(y_train_labeled,pred_l1_gs_train,average='micro')\n",
    "    train_prec_arr.append(train_prec)\n",
    "    test_prec = precision_score(y_test,pred_l1_gs_test,average='micro')\n",
    "    test_prec_arr.append(test_prec)\n",
    "    train_rec = recall_score(y_train_labeled,pred_l1_gs_train,average='micro')\n",
    "    train_rec_arr.append(train_rec)\n",
    "    test_rec = recall_score(y_test,pred_l1_gs_test,average='micro')\n",
    "    test_rec_arr.append(test_rec)\n",
    "    train_f1 = f1_score(y_train_labeled,pred_l1_gs_train,average='micro')\n",
    "    train_f1_arr.append(train_f1)\n",
    "    test_f1 = f1_score(y_test,pred_l1_gs_test,average='micro')\n",
    "    test_f1_arr.append(test_f1)\n",
    "    train_auc = roc_auc_score(y_train_labeled,le.transform(pred_l1_gs_train))\n",
    "    train_auc_arr.append(train_auc)\n",
    "    test_auc = roc_auc_score(y_test,le.transform(pred_l1_gs_test))\n",
    "    test_auc_arr.append(test_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cbcd721a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train scores: \n",
      "Accuracy: 0.9955752212389378\n",
      "Precision: 0.9955752212389378\n",
      "Recall: 0.9955752212389378\n",
      "F1: 0.9955752212389378\n",
      "AUC: 0.9942528735632185\n",
      "Test scores: \n",
      "Accuracy: 0.982456140350877\n",
      "Precision: 0.982456140350877\n",
      "Recall: 0.982456140350877\n",
      "F1: 0.982456140350877\n",
      "AUC: 0.9811507936507939\n"
     ]
    }
   ],
   "source": [
    "print('Train scores: ')\n",
    "print('Accuracy: '+str(np.average(train_acc_arr)))\n",
    "print('Precision: '+str(np.average(train_prec_arr)))\n",
    "print('Recall: '+str(np.average(train_rec_arr)))\n",
    "print('F1: '+str(np.average(train_f1_arr)))\n",
    "print('AUC: '+str(np.average(train_auc_arr)))\n",
    "\n",
    "print('Test scores: ')\n",
    "print('Accuracy: '+str(np.average(test_acc_arr)))\n",
    "print('Precision: '+str(np.average(test_prec_arr)))\n",
    "print('Recall: '+str(np.average(test_rec_arr)))\n",
    "print('F1: '+str(np.average(test_f1_arr)))\n",
    "print('AUC: '+str(np.average(test_auc_arr)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ca8262",
   "metadata": {},
   "source": [
    "##### B. Find the unlabeled data point that is the farthest to the decision boundary of the SVM. Let the SVM label it (ignore its true label), and add it to the labeled data, and retrain the SVM. Continue this process until all unlabeled data are used. Test the final SVM on the test data andthe average accuracy, precision, recall, F1-score, and AUC, for both training and test sets over your M runs. Plot the ROC and report the confusion matrix for training and testing in one of the runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ecce6e6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "442    -1\n",
       "111    -1\n",
       "187    -1\n",
       "417    -1\n",
       "226    -1\n",
       "       ..\n",
       "154    -1\n",
       "380    -1\n",
       "150    -1\n",
       "432    -1\n",
       "52     -1\n",
       "Name: Diagnosis, Length: 229, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_norm_df_unlabeled = X_train_norm_df[random_unlabeled_points]\n",
    "y_train_unlabeled = y_train[random_unlabeled_points]\n",
    "y_train_unlabeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c1bbac72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_norm_df_unlabeled = X_train_norm_df_unlabeled.reset_index().drop(columns='index')\n",
    "# X_train_norm_df_labeled = X_train_norm_df_labeled.reset_index().drop(columns='index')\n",
    "# y_train_labeled = y_train_labeled.sort_index().reset_index().drop(columns='index')['Diagnosis']\n",
    "# y_train_unlabeled = y_train_unlabeled.sort_index().reset_index().drop(columns='index')['Diagnosis']\n",
    "# y_train_labeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "42812ef7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mean_radius                1.604809\n",
       "SE_radius                 -0.095647\n",
       "Worst_radius               1.617386\n",
       "Mean_texture               1.704938\n",
       "SE_texture                 1.381162\n",
       "Worst_texture              1.123045\n",
       "Mean_perimeter             1.631363\n",
       "SE_perimeter               1.514725\n",
       "Worst_perimeter           -0.073859\n",
       "Mean_area                  0.363227\n",
       "SE_area                    2.647727\n",
       "Worst_area                -0.109130\n",
       "Mean_smoothness            2.250063\n",
       "SE_smoothness              2.268813\n",
       "Worst_smoothness          -0.331006\n",
       "Mean_compactness           0.371312\n",
       "SE_compactness             0.756091\n",
       "Worst_compactness          0.892954\n",
       "Mean_concavity            -0.194802\n",
       "SE_concavity               0.387773\n",
       "Worst_concavity            2.047868\n",
       "Mean_concave_points        0.070517\n",
       "SE_concave_points          1.940355\n",
       "Worst_concave_points       2.152966\n",
       "Mean_symmetry              0.739437\n",
       "SE_symmetry                0.962836\n",
       "Worst_symmetry             1.576656\n",
       "Mean_fractal_dimension     1.270339\n",
       "SE_fractal_dimension       0.096821\n",
       "Worst_fractal_dimension    0.824071\n",
       "Name: 240, dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_norm_df_labeled.iloc[129]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "31c2f5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(0,229):\n",
    "    l1_svc = LinearSVC(penalty='l1',loss='squared_hinge',dual=False ,random_state=i)\n",
    "    test_params = {'C':[0.02,0.03,0.04, 0.05,0.06,0.07,0.1]}\n",
    "#     print(i)\n",
    "    l1_svc_gs = GridSearchCV(estimator = l1_svc, param_grid = test_params,cv=5).\\\n",
    "    fit(X_train_norm_df_labeled,y_train_labeled)\n",
    "#     print(l1_svc_gs.best_estimator_)\n",
    "    max_dis = max(abs(l1_svc_gs.decision_function(X_train_norm_df_unlabeled)))\n",
    "#     print(max_dis)\n",
    "    max_ind = np.where(abs(l1_svc_gs.decision_function(X_train_norm_df_unlabeled)) == max_dis)[0][0]\n",
    "#     print(abs(l1_svc_gs.decision_function(X_train_norm_df_unlabeled)))\n",
    "#     print(X_train_norm_df_unlabeled.index[max_ind])\n",
    "    real_ind = X_train_norm_df_unlabeled.index[max_ind]\n",
    "    y_train_labeled.loc[max(y_train_labeled.index)+1] = l1_svc_gs.predict(X_train_norm_df_unlabeled.\\\n",
    "                                                                          iloc[max_ind:max_ind+1])[0]\n",
    "    X_train_norm_df_labeled.loc[max(X_train_norm_df_labeled.index)+1] = X_train_norm_df_unlabeled.iloc[max_ind]\n",
    "    X_train_norm_df_unlabeled = X_train_norm_df_unlabeled.drop(index=real_ind)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5183713b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC(C=0.03, dual=False, penalty='l1', random_state=8443008)\n",
      "LinearSVC(C=0.03, dual=False, penalty='l1', random_state=160390951)\n",
      "LinearSVC(C=0.03, dual=False, penalty='l1', random_state=311869477)\n",
      "LinearSVC(C=0.03, dual=False, penalty='l1', random_state=496547442)\n",
      "LinearSVC(C=0.03, dual=False, penalty='l1', random_state=180870768)\n",
      "LinearSVC(C=0.03, dual=False, penalty='l1', random_state=445336289)\n",
      "LinearSVC(C=0.03, dual=False, penalty='l1', random_state=318275370)\n",
      "LinearSVC(C=0.03, dual=False, penalty='l1', random_state=342505757)\n",
      "LinearSVC(C=0.03, dual=False, penalty='l1', random_state=439587497)\n",
      "LinearSVC(C=0.03, dual=False, penalty='l1', random_state=185726978)\n",
      "LinearSVC(C=0.03, dual=False, penalty='l1', random_state=52799365)\n",
      "LinearSVC(C=0.03, dual=False, penalty='l1', random_state=124454811)\n",
      "LinearSVC(C=0.03, dual=False, penalty='l1', random_state=355632828)\n",
      "LinearSVC(C=0.03, dual=False, penalty='l1', random_state=388845676)\n",
      "LinearSVC(C=0.03, dual=False, penalty='l1', random_state=328821602)\n",
      "LinearSVC(C=0.03, dual=False, penalty='l1', random_state=25624756)\n",
      "LinearSVC(C=0.03, dual=False, penalty='l1', random_state=130277815)\n",
      "LinearSVC(C=0.03, dual=False, penalty='l1', random_state=327415432)\n",
      "LinearSVC(C=0.03, dual=False, penalty='l1', random_state=421996527)\n",
      "LinearSVC(C=0.03, dual=False, penalty='l1', random_state=18625538)\n",
      "LinearSVC(C=0.03, dual=False, penalty='l1', random_state=218492950)\n",
      "LinearSVC(C=0.03, dual=False, penalty='l1', random_state=97068615)\n",
      "LinearSVC(C=0.03, dual=False, penalty='l1', random_state=93114985)\n",
      "LinearSVC(C=0.03, dual=False, penalty='l1', random_state=375666491)\n",
      "LinearSVC(C=0.03, dual=False, penalty='l1', random_state=91697285)\n",
      "LinearSVC(C=0.03, dual=False, penalty='l1', random_state=342903215)\n",
      "LinearSVC(C=0.03, dual=False, penalty='l1', random_state=85001814)\n",
      "LinearSVC(C=0.03, dual=False, penalty='l1', random_state=286377195)\n",
      "LinearSVC(C=0.03, dual=False, penalty='l1', random_state=279798626)\n",
      "LinearSVC(C=0.03, dual=False, penalty='l1', random_state=132396086)\n"
     ]
    }
   ],
   "source": [
    "train_acc_arr = []\n",
    "test_acc_arr = []\n",
    "train_prec_arr = []\n",
    "test_prec_arr = []\n",
    "train_rec_arr = []\n",
    "test_rec_arr = []\n",
    "train_f1_arr = []\n",
    "test_f1_arr = []\n",
    "train_auc_arr = []\n",
    "test_auc_arr = []\n",
    "for i in Ran_num:\n",
    "    l1_svc = LinearSVC(penalty='l1',loss='squared_hinge',dual=False ,random_state=i)\n",
    "    test_params = {'C':[0.02,0.03,0.04, 0.05,0.06,0.07,0.1]}\n",
    "\n",
    "    l1_svc_gs = GridSearchCV(estimator = l1_svc, param_grid = test_params,cv=5).\\\n",
    "    fit(X_train_norm_df_labeled,y_train_labeled)\n",
    "    print(l1_svc_gs.best_estimator_)\n",
    "    \n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit(y_train_labeled)\n",
    "    \n",
    "    pred_l1_gs_train = l1_svc_gs.predict(X_train_norm_df_labeled)\n",
    "    pred_l1_gs_test = l1_svc_gs.predict(X_test_norm_df)\n",
    "    train_acc = accuracy_score(y_train_labeled,pred_l1_gs_train)\n",
    "    train_acc_arr.append(train_acc)\n",
    "    test_acc = accuracy_score(y_test,pred_l1_gs_test)\n",
    "    test_acc_arr.append(test_acc)\n",
    "    train_prec = precision_score(y_train_labeled,pred_l1_gs_train,average='micro')\n",
    "    train_prec_arr.append(train_prec)\n",
    "    test_prec = precision_score(y_test,pred_l1_gs_test,average='micro')\n",
    "    test_prec_arr.append(test_prec)\n",
    "    train_rec = recall_score(y_train_labeled,pred_l1_gs_train,average='micro')\n",
    "    train_rec_arr.append(train_rec)\n",
    "    test_rec = recall_score(y_test,pred_l1_gs_test,average='micro')\n",
    "    test_rec_arr.append(test_rec)\n",
    "    train_f1 = f1_score(y_train_labeled,pred_l1_gs_train,average='micro')\n",
    "    train_f1_arr.append(train_f1)\n",
    "    test_f1 = f1_score(y_test,pred_l1_gs_test,average='micro')\n",
    "    test_f1_arr.append(test_f1)\n",
    "    train_auc = roc_auc_score(y_train_labeled,le.transform(pred_l1_gs_train))\n",
    "    train_auc_arr.append(train_auc)\n",
    "    test_auc = roc_auc_score(y_test,le.transform(pred_l1_gs_test))\n",
    "    test_auc_arr.append(test_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8346949c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train scores: \n",
      "Accuracy: 0.9912087912087912\n",
      "Precision: 0.9912087912087912\n",
      "Recall: 0.9912087912087912\n",
      "F1: 0.9912087912087912\n",
      "AUC: 0.9906524776070343\n",
      "Test scores: \n",
      "Accuracy: 0.9385964912280699\n",
      "Precision: 0.9385964912280699\n",
      "Recall: 0.9385964912280699\n",
      "F1: 0.9385964912280699\n",
      "AUC: 0.9365079365079365\n"
     ]
    }
   ],
   "source": [
    "print('Train scores: ')\n",
    "print('Accuracy: '+str(np.average(train_acc_arr)))\n",
    "print('Precision: '+str(np.average(train_prec_arr)))\n",
    "print('Recall: '+str(np.average(train_rec_arr)))\n",
    "print('F1: '+str(np.average(train_f1_arr)))\n",
    "print('AUC: '+str(np.average(train_auc_arr)))\n",
    "\n",
    "print('Test scores: ')\n",
    "print('Accuracy: '+str(np.average(test_acc_arr)))\n",
    "print('Precision: '+str(np.average(test_prec_arr)))\n",
    "print('Recall: '+str(np.average(test_rec_arr)))\n",
    "print('F1: '+str(np.average(test_f1_arr)))\n",
    "print('AUC: '+str(np.average(test_auc_arr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7fed5916",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function plot_roc_curve is deprecated; Function :func:`plot_roc_curve` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: :meth:`sklearn.metric.RocCurveDisplay.from_predictions` or :meth:`sklearn.metric.RocCurveDisplay.from_estimator`.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_roc_curve(l1_svc_gs, X_train_norm_df_labeled, y_train_labeled) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "207cb3a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function plot_roc_curve is deprecated; Function :func:`plot_roc_curve` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: :meth:`sklearn.metric.RocCurveDisplay.from_predictions` or :meth:`sklearn.metric.RocCurveDisplay.from_estimator`.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_roc_curve(l1_svc_gs, X_test_norm_df, y_test) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0300dd43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train condfusion matrix: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[281,   2],\n",
       "       [  2, 170]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('train condfusion matrix: ')\n",
    "confusion_matrix(y_train_labeled, pred_l1_gs_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cc89e4f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test condfusion matrix: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[68,  4],\n",
       "       [ 3, 39]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "print('test condfusion matrix: ')\n",
    "confusion_matrix(y_test, pred_l1_gs_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a39d78",
   "metadata": {},
   "source": [
    "#### iii. Unsupervised Learning: Run k-means algorithm on the whole training set. Ignore the labels of the data, and assume k = 2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83cb6f7f",
   "metadata": {},
   "source": [
    "#####  A. Run the k-means algorithm multiple times. Make sure that you initialize the algoritm randomly. How do you make sure that the algorithm was not trapped in a local minimum?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11debd6",
   "metadata": {},
   "source": [
    "Increse the number of initiatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "48b7b323",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.2, random_state=24,stratify=y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d75c8f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc_arr = []\n",
    "train_prec_arr = []\n",
    "train_rec_arr = []\n",
    "train_f1_arr = []\n",
    "train_auc_arr = []\n",
    "for i in Ran_num:\n",
    "    kmeans = KMeans(n_clusters=2, random_state=i,n_init = 50).fit(X_train)\n",
    "    dist_ = kmeans.transform(X_train)\n",
    "    pred_ = kmeans.predict(X_train)\n",
    "    df1 = pd.DataFrame(dist_,columns=['dist_to_C1','dist_to_C2'])\n",
    "    df1['true_label'] = y_train.values\n",
    "    df1['pred_label'] = pred_\n",
    "    close_to_c1 = df1.sort_values(by='dist_to_C1')[:30]\n",
    "    close_to_c2 = df1.sort_values(by='dist_to_C2')[:30]\n",
    "    c1_label = close_to_c1['true_label'].mode()[0]\n",
    "#     print(c1_label)\n",
    "    c2_label = close_to_c2['true_label'].mode()[0]\n",
    "\n",
    "    df1['pre_label_encode'] = df1['pred_label'].replace([0,1], [c1_label,c2_label])\n",
    "    df1['true_label_encode'] = df1['true_label'].replace(['M','B'], [0,1])\n",
    "    df1['pre_label_encode2'] = df1['pre_label_encode'].replace(['M','B'], [0,1])    \n",
    "    train_acc = accuracy_score(df1['true_label_encode'],df1['pre_label_encode2'])\n",
    "    train_acc_arr.append(train_acc)\n",
    "    train_prec = precision_score(df1['true_label_encode'],df1['pre_label_encode2'],average='micro')\n",
    "    train_prec_arr.append(train_prec)\n",
    "    train_rec = recall_score(df1['true_label_encode'],df1['pre_label_encode2'],average='micro')\n",
    "    train_rec_arr.append(train_rec)\n",
    "    train_f1 = f1_score(df1['true_label_encode'],df1['pre_label_encode2'],average='micro')\n",
    "    train_f1_arr.append(train_f1)\n",
    "    train_auc = roc_auc_score(df1['true_label_encode'],df1['pre_label_encode2'])\n",
    "    train_auc_arr.append(train_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0bac9d95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train scores: \n",
      "Accuracy: 0.8461538461538463\n",
      "Precision: 0.8461538461538463\n",
      "Recall: 0.8461538461538463\n",
      "F1: 0.8461538461538463\n",
      "AUC: 0.7953044375644996\n"
     ]
    }
   ],
   "source": [
    "print('Train scores: ')\n",
    "print('Accuracy: '+str(np.average(train_acc_arr)))\n",
    "print('Precision: '+str(np.average(train_prec_arr)))\n",
    "print('Recall: '+str(np.average(train_rec_arr)))\n",
    "print('F1: '+str(np.average(train_f1_arr)))\n",
    "print('AUC: '+str(np.average(train_auc_arr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e01f2198",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fpr, tpr, thresholds = metrics.roc_curve(df1['true_label_encode'], df1['pre_label_encode2'])\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "display = metrics.RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=roc_auc,estimator_name='Kmeans, n=2')\n",
    "display.plot()\n",
    "plt.show()\n",
    "# source: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.RocCurveDisplay.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "20add1ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[101,  69],\n",
       "       [  1, 284]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(df1['true_label_encode'], df1['pre_label_encode2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87cb8427",
   "metadata": {},
   "source": [
    "##### C. Classify test data based on their proximity to the centers of the clusters. Report the average accuracy, precision, recall, F1-score, and AUC over M runs, and ROC and the confusion matrix for one of the runs for the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b89d3b13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c2/55q5nzv51vz59zgdv6yql13m0000gn/T/ipykernel_6450/2181955368.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['pred_label'][i] = 0\n",
      "/var/folders/c2/55q5nzv51vz59zgdv6yql13m0000gn/T/ipykernel_6450/2181955368.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['pred_label'][i] = 1\n",
      "/var/folders/c2/55q5nzv51vz59zgdv6yql13m0000gn/T/ipykernel_6450/2181955368.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['pred_label'][i] = 0\n",
      "/var/folders/c2/55q5nzv51vz59zgdv6yql13m0000gn/T/ipykernel_6450/2181955368.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['pred_label'][i] = 1\n",
      "/var/folders/c2/55q5nzv51vz59zgdv6yql13m0000gn/T/ipykernel_6450/2181955368.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['pred_label'][i] = 0\n",
      "/var/folders/c2/55q5nzv51vz59zgdv6yql13m0000gn/T/ipykernel_6450/2181955368.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['pred_label'][i] = 1\n",
      "/var/folders/c2/55q5nzv51vz59zgdv6yql13m0000gn/T/ipykernel_6450/2181955368.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['pred_label'][i] = 0\n",
      "/var/folders/c2/55q5nzv51vz59zgdv6yql13m0000gn/T/ipykernel_6450/2181955368.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['pred_label'][i] = 1\n",
      "/var/folders/c2/55q5nzv51vz59zgdv6yql13m0000gn/T/ipykernel_6450/2181955368.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['pred_label'][i] = 0\n",
      "/var/folders/c2/55q5nzv51vz59zgdv6yql13m0000gn/T/ipykernel_6450/2181955368.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['pred_label'][i] = 1\n",
      "/var/folders/c2/55q5nzv51vz59zgdv6yql13m0000gn/T/ipykernel_6450/2181955368.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['pred_label'][i] = 0\n",
      "/var/folders/c2/55q5nzv51vz59zgdv6yql13m0000gn/T/ipykernel_6450/2181955368.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['pred_label'][i] = 1\n",
      "/var/folders/c2/55q5nzv51vz59zgdv6yql13m0000gn/T/ipykernel_6450/2181955368.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['pred_label'][i] = 1\n",
      "/var/folders/c2/55q5nzv51vz59zgdv6yql13m0000gn/T/ipykernel_6450/2181955368.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['pred_label'][i] = 0\n",
      "/var/folders/c2/55q5nzv51vz59zgdv6yql13m0000gn/T/ipykernel_6450/2181955368.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['pred_label'][i] = 0\n",
      "/var/folders/c2/55q5nzv51vz59zgdv6yql13m0000gn/T/ipykernel_6450/2181955368.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['pred_label'][i] = 1\n",
      "/var/folders/c2/55q5nzv51vz59zgdv6yql13m0000gn/T/ipykernel_6450/2181955368.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['pred_label'][i] = 1\n",
      "/var/folders/c2/55q5nzv51vz59zgdv6yql13m0000gn/T/ipykernel_6450/2181955368.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['pred_label'][i] = 0\n",
      "/var/folders/c2/55q5nzv51vz59zgdv6yql13m0000gn/T/ipykernel_6450/2181955368.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['pred_label'][i] = 0\n",
      "/var/folders/c2/55q5nzv51vz59zgdv6yql13m0000gn/T/ipykernel_6450/2181955368.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['pred_label'][i] = 1\n",
      "/var/folders/c2/55q5nzv51vz59zgdv6yql13m0000gn/T/ipykernel_6450/2181955368.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['pred_label'][i] = 0\n",
      "/var/folders/c2/55q5nzv51vz59zgdv6yql13m0000gn/T/ipykernel_6450/2181955368.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['pred_label'][i] = 1\n",
      "/var/folders/c2/55q5nzv51vz59zgdv6yql13m0000gn/T/ipykernel_6450/2181955368.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['pred_label'][i] = 0\n",
      "/var/folders/c2/55q5nzv51vz59zgdv6yql13m0000gn/T/ipykernel_6450/2181955368.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['pred_label'][i] = 1\n",
      "/var/folders/c2/55q5nzv51vz59zgdv6yql13m0000gn/T/ipykernel_6450/2181955368.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['pred_label'][i] = 0\n",
      "/var/folders/c2/55q5nzv51vz59zgdv6yql13m0000gn/T/ipykernel_6450/2181955368.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['pred_label'][i] = 1\n",
      "/var/folders/c2/55q5nzv51vz59zgdv6yql13m0000gn/T/ipykernel_6450/2181955368.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['pred_label'][i] = 1\n",
      "/var/folders/c2/55q5nzv51vz59zgdv6yql13m0000gn/T/ipykernel_6450/2181955368.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['pred_label'][i] = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c2/55q5nzv51vz59zgdv6yql13m0000gn/T/ipykernel_6450/2181955368.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['pred_label'][i] = 0\n",
      "/var/folders/c2/55q5nzv51vz59zgdv6yql13m0000gn/T/ipykernel_6450/2181955368.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['pred_label'][i] = 1\n",
      "/var/folders/c2/55q5nzv51vz59zgdv6yql13m0000gn/T/ipykernel_6450/2181955368.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['pred_label'][i] = 0\n",
      "/var/folders/c2/55q5nzv51vz59zgdv6yql13m0000gn/T/ipykernel_6450/2181955368.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['pred_label'][i] = 1\n",
      "/var/folders/c2/55q5nzv51vz59zgdv6yql13m0000gn/T/ipykernel_6450/2181955368.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['pred_label'][i] = 1\n",
      "/var/folders/c2/55q5nzv51vz59zgdv6yql13m0000gn/T/ipykernel_6450/2181955368.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['pred_label'][i] = 0\n",
      "/var/folders/c2/55q5nzv51vz59zgdv6yql13m0000gn/T/ipykernel_6450/2181955368.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['pred_label'][i] = 0\n",
      "/var/folders/c2/55q5nzv51vz59zgdv6yql13m0000gn/T/ipykernel_6450/2181955368.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['pred_label'][i] = 1\n",
      "/var/folders/c2/55q5nzv51vz59zgdv6yql13m0000gn/T/ipykernel_6450/2181955368.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['pred_label'][i] = 0\n",
      "/var/folders/c2/55q5nzv51vz59zgdv6yql13m0000gn/T/ipykernel_6450/2181955368.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['pred_label'][i] = 1\n",
      "/var/folders/c2/55q5nzv51vz59zgdv6yql13m0000gn/T/ipykernel_6450/2181955368.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['pred_label'][i] = 0\n",
      "/var/folders/c2/55q5nzv51vz59zgdv6yql13m0000gn/T/ipykernel_6450/2181955368.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['pred_label'][i] = 1\n",
      "/var/folders/c2/55q5nzv51vz59zgdv6yql13m0000gn/T/ipykernel_6450/2181955368.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['pred_label'][i] = 1\n",
      "/var/folders/c2/55q5nzv51vz59zgdv6yql13m0000gn/T/ipykernel_6450/2181955368.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['pred_label'][i] = 0\n",
      "/var/folders/c2/55q5nzv51vz59zgdv6yql13m0000gn/T/ipykernel_6450/2181955368.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['pred_label'][i] = 1\n",
      "/var/folders/c2/55q5nzv51vz59zgdv6yql13m0000gn/T/ipykernel_6450/2181955368.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['pred_label'][i] = 0\n",
      "/var/folders/c2/55q5nzv51vz59zgdv6yql13m0000gn/T/ipykernel_6450/2181955368.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['pred_label'][i] = 0\n",
      "/var/folders/c2/55q5nzv51vz59zgdv6yql13m0000gn/T/ipykernel_6450/2181955368.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['pred_label'][i] = 1\n",
      "/var/folders/c2/55q5nzv51vz59zgdv6yql13m0000gn/T/ipykernel_6450/2181955368.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['pred_label'][i] = 0\n",
      "/var/folders/c2/55q5nzv51vz59zgdv6yql13m0000gn/T/ipykernel_6450/2181955368.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['pred_label'][i] = 1\n",
      "/var/folders/c2/55q5nzv51vz59zgdv6yql13m0000gn/T/ipykernel_6450/2181955368.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['pred_label'][i] = 1\n",
      "/var/folders/c2/55q5nzv51vz59zgdv6yql13m0000gn/T/ipykernel_6450/2181955368.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['pred_label'][i] = 0\n",
      "/var/folders/c2/55q5nzv51vz59zgdv6yql13m0000gn/T/ipykernel_6450/2181955368.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['pred_label'][i] = 0\n",
      "/var/folders/c2/55q5nzv51vz59zgdv6yql13m0000gn/T/ipykernel_6450/2181955368.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['pred_label'][i] = 1\n",
      "/var/folders/c2/55q5nzv51vz59zgdv6yql13m0000gn/T/ipykernel_6450/2181955368.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['pred_label'][i] = 0\n",
      "/var/folders/c2/55q5nzv51vz59zgdv6yql13m0000gn/T/ipykernel_6450/2181955368.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['pred_label'][i] = 1\n",
      "/var/folders/c2/55q5nzv51vz59zgdv6yql13m0000gn/T/ipykernel_6450/2181955368.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['pred_label'][i] = 0\n",
      "/var/folders/c2/55q5nzv51vz59zgdv6yql13m0000gn/T/ipykernel_6450/2181955368.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['pred_label'][i] = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c2/55q5nzv51vz59zgdv6yql13m0000gn/T/ipykernel_6450/2181955368.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['pred_label'][i] = 0\n",
      "/var/folders/c2/55q5nzv51vz59zgdv6yql13m0000gn/T/ipykernel_6450/2181955368.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['pred_label'][i] = 1\n",
      "/var/folders/c2/55q5nzv51vz59zgdv6yql13m0000gn/T/ipykernel_6450/2181955368.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['pred_label'][i] = 0\n",
      "/var/folders/c2/55q5nzv51vz59zgdv6yql13m0000gn/T/ipykernel_6450/2181955368.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['pred_label'][i] = 1\n"
     ]
    }
   ],
   "source": [
    "test_acc_arr = []\n",
    "test_prec_arr = []\n",
    "test_rec_arr = []\n",
    "test_f1_arr = []\n",
    "test_auc_arr = []\n",
    "for i in Ran_num:\n",
    "    kmeans = KMeans(n_clusters=2, random_state=i,n_init = 50).fit(X_train)\n",
    "    dist_ = kmeans.transform(X_test)\n",
    "    pred_ = kmeans.predict(X_test)\n",
    "    df1 = pd.DataFrame(dist_,columns=['dist_to_C1','dist_to_C2'])\n",
    "    df1['true_label'] = y_test.values\n",
    "    df1['pred_label'] = np.nan\n",
    "    for i in range(0,len(df1)):\n",
    "        if df1['dist_to_C1'][i] < df1['dist_to_C2'][i]:\n",
    "            df1['pred_label'][i] = 0\n",
    "        else:\n",
    "            df1['pred_label'][i] = 1\n",
    "    M_encode = df1[df1['true_label']=='M']['pred_label'].mode()[0]\n",
    "    B_encode = df1[df1['true_label']=='B']['pred_label'].mode()[0]\n",
    "    df1['true_label_encode'] = df1['true_label']\n",
    "    df1['true_label_encode'] = df1['true_label_encode'].replace(['M','B'], [M_encode,B_encode])\n",
    "    \n",
    "\n",
    "    test_acc = accuracy_score(df1['true_label_encode'],df1['pred_label'])\n",
    "    test_acc_arr.append(test_acc)\n",
    "    test_prec = precision_score(df1['true_label_encode'],df1['pred_label'],average='micro')\n",
    "    test_prec_arr.append(test_prec)\n",
    "    test_rec = recall_score(df1['true_label_encode'],df1['pred_label'],average='micro')\n",
    "    test_rec_arr.append(test_rec)\n",
    "    test_f1 = f1_score(df1['true_label_encode'],df1['pred_label'],average='micro')\n",
    "    test_f1_arr.append(test_f1)\n",
    "    test_auc = roc_auc_score(df1['true_label_encode'],df1['pred_label'])\n",
    "    test_auc_arr.append(test_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "aa8532df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test scores: \n",
      "Accuracy: 0.8859649122807018\n",
      "Precision: 0.8859649122807018\n",
      "Recall: 0.8859649122807018\n",
      "F1: 0.8859649122807018\n",
      "AUC: 0.8452380952380951\n"
     ]
    }
   ],
   "source": [
    "print('Test scores: ')\n",
    "print('Accuracy: '+str(np.average(test_acc_arr)))\n",
    "print('Precision: '+str(np.average(test_prec_arr)))\n",
    "print('Recall: '+str(np.average(test_rec_arr)))\n",
    "print('F1: '+str(np.average(test_f1_arr)))\n",
    "print('AUC: '+str(np.average(test_auc_arr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "800de75c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fpr, tpr, thresholds = metrics.roc_curve(df1['true_label_encode'],df1['pred_label'])\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "display = metrics.RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=roc_auc,estimator_name='Kmeans, n=2')\n",
    "display.plot()\n",
    "plt.show()\n",
    "# source: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.RocCurveDisplay.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d93f2ac6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[72,  0],\n",
       "       [13, 29]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(df1['true_label_encode'],df1['pred_label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3689b4",
   "metadata": {},
   "source": [
    "#### iv. Spectral Clustering: Repeat 1(b)iii using spectral clustering, which is clustering based on kernels.3 Research what spectral clustering is. Use RBF kernel with gamma=1 or find a gamma for which the two clutsres have the same balance as the one in original data set (if the positive class has p and the negative class has n samples, the two clusters must have p and n members). Do not label data based on their proximity to cluster center, because spectral clustering may give you non-convex clusters . Instead, use fit − predict method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "49061858",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean_radius</th>\n",
       "      <th>SE_radius</th>\n",
       "      <th>Worst_radius</th>\n",
       "      <th>Mean_texture</th>\n",
       "      <th>SE_texture</th>\n",
       "      <th>Worst_texture</th>\n",
       "      <th>Mean_perimeter</th>\n",
       "      <th>SE_perimeter</th>\n",
       "      <th>Worst_perimeter</th>\n",
       "      <th>Mean_area</th>\n",
       "      <th>...</th>\n",
       "      <th>Worst_concavity</th>\n",
       "      <th>Mean_concave_points</th>\n",
       "      <th>SE_concave_points</th>\n",
       "      <th>Worst_concave_points</th>\n",
       "      <th>Mean_symmetry</th>\n",
       "      <th>SE_symmetry</th>\n",
       "      <th>Worst_symmetry</th>\n",
       "      <th>Mean_fractal_dimension</th>\n",
       "      <th>SE_fractal_dimension</th>\n",
       "      <th>Worst_fractal_dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>15.19</td>\n",
       "      <td>13.21</td>\n",
       "      <td>97.65</td>\n",
       "      <td>711.8</td>\n",
       "      <td>0.07963</td>\n",
       "      <td>0.06934</td>\n",
       "      <td>0.03393</td>\n",
       "      <td>0.026570</td>\n",
       "      <td>0.1721</td>\n",
       "      <td>0.05544</td>\n",
       "      <td>...</td>\n",
       "      <td>16.20</td>\n",
       "      <td>15.73</td>\n",
       "      <td>104.50</td>\n",
       "      <td>819.1</td>\n",
       "      <td>0.11260</td>\n",
       "      <td>0.17370</td>\n",
       "      <td>0.13620</td>\n",
       "      <td>0.08178</td>\n",
       "      <td>0.2487</td>\n",
       "      <td>0.06766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>10.20</td>\n",
       "      <td>17.48</td>\n",
       "      <td>65.05</td>\n",
       "      <td>321.2</td>\n",
       "      <td>0.08054</td>\n",
       "      <td>0.05907</td>\n",
       "      <td>0.05774</td>\n",
       "      <td>0.010710</td>\n",
       "      <td>0.1964</td>\n",
       "      <td>0.06315</td>\n",
       "      <td>...</td>\n",
       "      <td>11.48</td>\n",
       "      <td>24.47</td>\n",
       "      <td>75.40</td>\n",
       "      <td>403.7</td>\n",
       "      <td>0.09527</td>\n",
       "      <td>0.13970</td>\n",
       "      <td>0.19250</td>\n",
       "      <td>0.03571</td>\n",
       "      <td>0.2868</td>\n",
       "      <td>0.07809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19.81</td>\n",
       "      <td>22.15</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1260.0</td>\n",
       "      <td>0.09831</td>\n",
       "      <td>0.10270</td>\n",
       "      <td>0.14790</td>\n",
       "      <td>0.094980</td>\n",
       "      <td>0.1582</td>\n",
       "      <td>0.05395</td>\n",
       "      <td>...</td>\n",
       "      <td>27.32</td>\n",
       "      <td>30.88</td>\n",
       "      <td>186.80</td>\n",
       "      <td>2398.0</td>\n",
       "      <td>0.15120</td>\n",
       "      <td>0.31500</td>\n",
       "      <td>0.53720</td>\n",
       "      <td>0.23880</td>\n",
       "      <td>0.2768</td>\n",
       "      <td>0.07615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>13.78</td>\n",
       "      <td>15.79</td>\n",
       "      <td>88.37</td>\n",
       "      <td>585.9</td>\n",
       "      <td>0.08817</td>\n",
       "      <td>0.06718</td>\n",
       "      <td>0.01055</td>\n",
       "      <td>0.009937</td>\n",
       "      <td>0.1405</td>\n",
       "      <td>0.05848</td>\n",
       "      <td>...</td>\n",
       "      <td>15.27</td>\n",
       "      <td>17.50</td>\n",
       "      <td>97.90</td>\n",
       "      <td>706.6</td>\n",
       "      <td>0.10720</td>\n",
       "      <td>0.10710</td>\n",
       "      <td>0.03517</td>\n",
       "      <td>0.03312</td>\n",
       "      <td>0.1859</td>\n",
       "      <td>0.06810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>12.63</td>\n",
       "      <td>20.76</td>\n",
       "      <td>82.15</td>\n",
       "      <td>480.4</td>\n",
       "      <td>0.09933</td>\n",
       "      <td>0.12090</td>\n",
       "      <td>0.10650</td>\n",
       "      <td>0.060210</td>\n",
       "      <td>0.1735</td>\n",
       "      <td>0.07070</td>\n",
       "      <td>...</td>\n",
       "      <td>13.33</td>\n",
       "      <td>25.47</td>\n",
       "      <td>89.00</td>\n",
       "      <td>527.4</td>\n",
       "      <td>0.12870</td>\n",
       "      <td>0.22500</td>\n",
       "      <td>0.22160</td>\n",
       "      <td>0.11050</td>\n",
       "      <td>0.2226</td>\n",
       "      <td>0.08486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>20.18</td>\n",
       "      <td>19.54</td>\n",
       "      <td>133.80</td>\n",
       "      <td>1250.0</td>\n",
       "      <td>0.11330</td>\n",
       "      <td>0.14890</td>\n",
       "      <td>0.21330</td>\n",
       "      <td>0.125900</td>\n",
       "      <td>0.1724</td>\n",
       "      <td>0.06053</td>\n",
       "      <td>...</td>\n",
       "      <td>22.03</td>\n",
       "      <td>25.07</td>\n",
       "      <td>146.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.16650</td>\n",
       "      <td>0.29420</td>\n",
       "      <td>0.53080</td>\n",
       "      <td>0.21730</td>\n",
       "      <td>0.3032</td>\n",
       "      <td>0.08075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>13.74</td>\n",
       "      <td>17.91</td>\n",
       "      <td>88.12</td>\n",
       "      <td>585.0</td>\n",
       "      <td>0.07944</td>\n",
       "      <td>0.06376</td>\n",
       "      <td>0.02881</td>\n",
       "      <td>0.013290</td>\n",
       "      <td>0.1473</td>\n",
       "      <td>0.05580</td>\n",
       "      <td>...</td>\n",
       "      <td>15.34</td>\n",
       "      <td>22.46</td>\n",
       "      <td>97.19</td>\n",
       "      <td>725.9</td>\n",
       "      <td>0.09711</td>\n",
       "      <td>0.18240</td>\n",
       "      <td>0.15640</td>\n",
       "      <td>0.06019</td>\n",
       "      <td>0.2350</td>\n",
       "      <td>0.07014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>11.94</td>\n",
       "      <td>18.24</td>\n",
       "      <td>75.71</td>\n",
       "      <td>437.6</td>\n",
       "      <td>0.08261</td>\n",
       "      <td>0.04751</td>\n",
       "      <td>0.01972</td>\n",
       "      <td>0.013490</td>\n",
       "      <td>0.1868</td>\n",
       "      <td>0.06110</td>\n",
       "      <td>...</td>\n",
       "      <td>13.10</td>\n",
       "      <td>21.33</td>\n",
       "      <td>83.67</td>\n",
       "      <td>527.2</td>\n",
       "      <td>0.11440</td>\n",
       "      <td>0.08906</td>\n",
       "      <td>0.09203</td>\n",
       "      <td>0.06296</td>\n",
       "      <td>0.2785</td>\n",
       "      <td>0.07408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>28.11</td>\n",
       "      <td>18.47</td>\n",
       "      <td>188.50</td>\n",
       "      <td>2499.0</td>\n",
       "      <td>0.11420</td>\n",
       "      <td>0.15160</td>\n",
       "      <td>0.32010</td>\n",
       "      <td>0.159500</td>\n",
       "      <td>0.1648</td>\n",
       "      <td>0.05525</td>\n",
       "      <td>...</td>\n",
       "      <td>28.11</td>\n",
       "      <td>18.47</td>\n",
       "      <td>188.50</td>\n",
       "      <td>2499.0</td>\n",
       "      <td>0.11420</td>\n",
       "      <td>0.15160</td>\n",
       "      <td>0.32010</td>\n",
       "      <td>0.15950</td>\n",
       "      <td>0.1648</td>\n",
       "      <td>0.05525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>15.06</td>\n",
       "      <td>19.83</td>\n",
       "      <td>100.30</td>\n",
       "      <td>705.6</td>\n",
       "      <td>0.10390</td>\n",
       "      <td>0.15530</td>\n",
       "      <td>0.17000</td>\n",
       "      <td>0.088150</td>\n",
       "      <td>0.1855</td>\n",
       "      <td>0.06284</td>\n",
       "      <td>...</td>\n",
       "      <td>18.23</td>\n",
       "      <td>24.23</td>\n",
       "      <td>123.50</td>\n",
       "      <td>1025.0</td>\n",
       "      <td>0.15510</td>\n",
       "      <td>0.42030</td>\n",
       "      <td>0.52030</td>\n",
       "      <td>0.21150</td>\n",
       "      <td>0.2834</td>\n",
       "      <td>0.08234</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>455 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Mean_radius  SE_radius  Worst_radius  Mean_texture  SE_texture  \\\n",
       "371        15.19      13.21         97.65         711.8     0.07963   \n",
       "217        10.20      17.48         65.05         321.2     0.08054   \n",
       "18         19.81      22.15        130.00        1260.0     0.09831   \n",
       "442        13.78      15.79         88.37         585.9     0.08817   \n",
       "111        12.63      20.76         82.15         480.4     0.09933   \n",
       "..           ...        ...           ...           ...         ...   \n",
       "432        20.18      19.54        133.80        1250.0     0.11330   \n",
       "149        13.74      17.91         88.12         585.0     0.07944   \n",
       "52         11.94      18.24         75.71         437.6     0.08261   \n",
       "212        28.11      18.47        188.50        2499.0     0.11420   \n",
       "94         15.06      19.83        100.30         705.6     0.10390   \n",
       "\n",
       "     Worst_texture  Mean_perimeter  SE_perimeter  Worst_perimeter  Mean_area  \\\n",
       "371        0.06934         0.03393      0.026570           0.1721    0.05544   \n",
       "217        0.05907         0.05774      0.010710           0.1964    0.06315   \n",
       "18         0.10270         0.14790      0.094980           0.1582    0.05395   \n",
       "442        0.06718         0.01055      0.009937           0.1405    0.05848   \n",
       "111        0.12090         0.10650      0.060210           0.1735    0.07070   \n",
       "..             ...             ...           ...              ...        ...   \n",
       "432        0.14890         0.21330      0.125900           0.1724    0.06053   \n",
       "149        0.06376         0.02881      0.013290           0.1473    0.05580   \n",
       "52         0.04751         0.01972      0.013490           0.1868    0.06110   \n",
       "212        0.15160         0.32010      0.159500           0.1648    0.05525   \n",
       "94         0.15530         0.17000      0.088150           0.1855    0.06284   \n",
       "\n",
       "     ...  Worst_concavity  Mean_concave_points  SE_concave_points  \\\n",
       "371  ...            16.20                15.73             104.50   \n",
       "217  ...            11.48                24.47              75.40   \n",
       "18   ...            27.32                30.88             186.80   \n",
       "442  ...            15.27                17.50              97.90   \n",
       "111  ...            13.33                25.47              89.00   \n",
       "..   ...              ...                  ...                ...   \n",
       "432  ...            22.03                25.07             146.00   \n",
       "149  ...            15.34                22.46              97.19   \n",
       "52   ...            13.10                21.33              83.67   \n",
       "212  ...            28.11                18.47             188.50   \n",
       "94   ...            18.23                24.23             123.50   \n",
       "\n",
       "     Worst_concave_points  Mean_symmetry  SE_symmetry  Worst_symmetry  \\\n",
       "371                 819.1        0.11260      0.17370         0.13620   \n",
       "217                 403.7        0.09527      0.13970         0.19250   \n",
       "18                 2398.0        0.15120      0.31500         0.53720   \n",
       "442                 706.6        0.10720      0.10710         0.03517   \n",
       "111                 527.4        0.12870      0.22500         0.22160   \n",
       "..                    ...            ...          ...             ...   \n",
       "432                1479.0        0.16650      0.29420         0.53080   \n",
       "149                 725.9        0.09711      0.18240         0.15640   \n",
       "52                  527.2        0.11440      0.08906         0.09203   \n",
       "212                2499.0        0.11420      0.15160         0.32010   \n",
       "94                 1025.0        0.15510      0.42030         0.52030   \n",
       "\n",
       "     Mean_fractal_dimension  SE_fractal_dimension  Worst_fractal_dimension  \n",
       "371                 0.08178                0.2487                  0.06766  \n",
       "217                 0.03571                0.2868                  0.07809  \n",
       "18                  0.23880                0.2768                  0.07615  \n",
       "442                 0.03312                0.1859                  0.06810  \n",
       "111                 0.11050                0.2226                  0.08486  \n",
       "..                      ...                   ...                      ...  \n",
       "432                 0.21730                0.3032                  0.08075  \n",
       "149                 0.06019                0.2350                  0.07014  \n",
       "52                  0.06296                0.2785                  0.07408  \n",
       "212                 0.15950                0.1648                  0.05525  \n",
       "94                  0.21150                0.2834                  0.08234  \n",
       "\n",
       "[455 rows x 30 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train\n",
    "# Here used all the train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b85c72f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc_arr = []\n",
    "train_prec_arr = []\n",
    "train_rec_arr = []\n",
    "train_f1_arr = []\n",
    "train_auc_arr = []\n",
    "for i in Ran_num:\n",
    "    SC = SpectralClustering(n_clusters=2,gamma=0.00000001, random_state=i,assign_labels='discretize',\\\n",
    "                                eigen_solver='arpack').fit_predict(X_train)\n",
    "\n",
    "    df1 = pd.DataFrame(SC,columns=['pre_label'])\n",
    "    df1['true_label'] = y_train.values\n",
    "    label_0 = df1[df1['pre_label'] == 0]['true_label'].mode()[0]\n",
    "    label_1 = df1[df1['pre_label'] == 1]['true_label'].mode()[0]\n",
    "    df1['pre_label_encoded'] = df1['pre_label'].replace([0,1], [label_0,label_1])\n",
    "    df1['true_label_encoded'] = df1['true_label'].replace(['B','M'], [0,1])\n",
    "    df1['pre_label_encoded2'] = df1['pre_label_encoded'].replace(['B','M'], [0,1])\n",
    "\n",
    "    train_acc = accuracy_score(df1['true_label_encoded'],df1['pre_label_encoded2'])\n",
    "    train_acc_arr.append(train_acc)\n",
    "    train_prec = precision_score(df1['true_label_encoded'],df1['pre_label_encoded2'],average='micro')\n",
    "    train_prec_arr.append(train_prec)\n",
    "    train_rec = recall_score(df1['true_label_encoded'],df1['pre_label_encoded2'],average='micro')\n",
    "    train_rec_arr.append(train_rec)\n",
    "    train_f1 = f1_score(df1['true_label_encoded'],df1['pre_label_encoded2'],average='micro')\n",
    "    train_f1_arr.append(train_f1)\n",
    "    train_auc = roc_auc_score(df1['true_label_encoded'],df1['pre_label_encoded2'])\n",
    "    train_auc_arr.append(train_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4c24fb9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train scores: \n",
      "Accuracy: 0.8791208791208792\n",
      "Precision: 0.8791208791208792\n",
      "Recall: 0.8791208791208792\n",
      "F1: 0.8791208791208792\n",
      "AUC: 0.8417956656346747\n"
     ]
    }
   ],
   "source": [
    "print('Train scores: ')\n",
    "print('Accuracy: '+str(np.average(train_acc_arr)))\n",
    "print('Precision: '+str(np.average(train_prec_arr)))\n",
    "print('Recall: '+str(np.average(train_rec_arr)))\n",
    "print('F1: '+str(np.average(train_f1_arr)))\n",
    "print('AUC: '+str(np.average(train_auc_arr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c0562699",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fpr, tpr, thresholds = metrics.roc_curve(df1['true_label_encoded'], df1['pre_label_encoded2'])\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "display = metrics.RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=roc_auc,estimator_name='Kmeans, n=2')\n",
    "display.plot()\n",
    "plt.show()\n",
    "# source: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.RocCurveDisplay.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f96c11e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[282,   3],\n",
       "       [ 52, 118]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(df1['true_label_encoded'], df1['pre_label_encoded2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39754673",
   "metadata": {},
   "source": [
    "#### v. One can expect that supervised learning on the full data set works better than semi-supervised learning with half of the data set labeled.One can expect that unsupervised learning underperforms in such situations. Compare the results you obtained by those methods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be18dbb",
   "metadata": {},
   "source": [
    "Supervised-training F1-score: 0.9824\n",
    "\n",
    "Semi-supervised training F1-score: 0.9912\n",
    "\n",
    "Unsupervised training F1-score: 0.8791\n",
    "\n",
    "For expection 1: ''supervised learning on the full data set works better than semi-supervised learning with half of the data set labeled'' is not correct in my methods.\n",
    "\n",
    "For expection 2: ''unsupervised learning underperforms in such situations'' is correct. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e19930",
   "metadata": {},
   "source": [
    "<center><font size=\"4\">2. Active Learning Using Support Vector Machines</font></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "051caa38",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names2 = ['variance', 'skewness', 'curtosis', 'entropy', 'class' ]\n",
    "file_path2 = r'../../Data/Data/data_banknote_authentication.txt'\n",
    "dataset2 = pd.read_csv(file_path2, delimiter=\",\",names = feature_names2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0dff6a10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variance</th>\n",
       "      <th>skewness</th>\n",
       "      <th>curtosis</th>\n",
       "      <th>entropy</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.62160</td>\n",
       "      <td>8.66610</td>\n",
       "      <td>-2.8073</td>\n",
       "      <td>-0.44699</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.54590</td>\n",
       "      <td>8.16740</td>\n",
       "      <td>-2.4586</td>\n",
       "      <td>-1.46210</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.86600</td>\n",
       "      <td>-2.63830</td>\n",
       "      <td>1.9242</td>\n",
       "      <td>0.10645</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.45660</td>\n",
       "      <td>9.52280</td>\n",
       "      <td>-4.0112</td>\n",
       "      <td>-3.59440</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.32924</td>\n",
       "      <td>-4.45520</td>\n",
       "      <td>4.5718</td>\n",
       "      <td>-0.98880</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1367</th>\n",
       "      <td>0.40614</td>\n",
       "      <td>1.34920</td>\n",
       "      <td>-1.4501</td>\n",
       "      <td>-0.55949</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1368</th>\n",
       "      <td>-1.38870</td>\n",
       "      <td>-4.87730</td>\n",
       "      <td>6.4774</td>\n",
       "      <td>0.34179</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1369</th>\n",
       "      <td>-3.75030</td>\n",
       "      <td>-13.45860</td>\n",
       "      <td>17.5932</td>\n",
       "      <td>-2.77710</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1370</th>\n",
       "      <td>-3.56370</td>\n",
       "      <td>-8.38270</td>\n",
       "      <td>12.3930</td>\n",
       "      <td>-1.28230</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1371</th>\n",
       "      <td>-2.54190</td>\n",
       "      <td>-0.65804</td>\n",
       "      <td>2.6842</td>\n",
       "      <td>1.19520</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1372 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      variance  skewness  curtosis  entropy  class\n",
       "0      3.62160   8.66610   -2.8073 -0.44699      0\n",
       "1      4.54590   8.16740   -2.4586 -1.46210      0\n",
       "2      3.86600  -2.63830    1.9242  0.10645      0\n",
       "3      3.45660   9.52280   -4.0112 -3.59440      0\n",
       "4      0.32924  -4.45520    4.5718 -0.98880      0\n",
       "...        ...       ...       ...      ...    ...\n",
       "1367   0.40614   1.34920   -1.4501 -0.55949      1\n",
       "1368  -1.38870  -4.87730    6.4774  0.34179      1\n",
       "1369  -3.75030 -13.45860   17.5932 -2.77710      1\n",
       "1370  -3.56370  -8.38270   12.3930 -1.28230      1\n",
       "1371  -2.54190  -0.65804    2.6842  1.19520      1\n",
       "\n",
       "[1372 rows x 5 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e3fd0cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data2 = dataset2['class']\n",
    "X_data2 = dataset2.drop(labels=['class'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "10aad51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X_data2, y_data2, test_size=472, \\\n",
    "                                                        random_state=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2103797d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "407    0\n",
       "424    0\n",
       "691    0\n",
       "715    0\n",
       "685    0\n",
       "      ..\n",
       "145    0\n",
       "343    0\n",
       "192    0\n",
       "899    1\n",
       "418    0\n",
       "Name: class, Length: 900, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7f6fce",
   "metadata": {},
   "source": [
    "### (b) Repeat each of the following two procedures 50 times. You will have 50 errors for 90 SVMs per each procedure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e303335",
   "metadata": {},
   "source": [
    "#### i. Train a SVM with a pool of 10 randomly selected data points from the training set using linear kernel and L1 penalty. Select the penalty parameter using 5-fold cross validation.4 Repeat this process by adding 10 other randomly selected data points to the pool, until you use all the 900 points. Do NOT replace the samples back into the training set at each step. Calculate the test error for each SVM. You will have 90 SVMs that were trained using 10, 20, 30, ... , 900 data points and their 90 test errors. You have implemented passive learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "72684368",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ran_num2 = [random.randrange(1, 500000000, 1) for i in range(50)]\n",
    "len(Ran_num2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a7c84b83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "9 fits failed out of a total of 45.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "9 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_classes.py\", line 257, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 1143, in _fit_liblinear\n",
      "    raise ValueError(\n",
      "ValueError: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "for n in range(0,90):\n",
    "    locals() ['passive_error'+str(n)]  = []\n",
    "        \n",
    "for i in Ran_num:\n",
    "    samp_X_train2 = X_train2.sample(frac=1,random_state=i)\n",
    "    samp_y_train2 = y_train2.sample(frac=1,random_state=i)\n",
    "    for j in range(0,90):\n",
    "        locals() ['x_train_set'+str(j)] = samp_X_train2.iloc[:10*(j+1)]\n",
    "        locals() ['y_train_set'+str(j)] = samp_y_train2.iloc[:10*(j+1)]\n",
    "        l1_svc2 = LinearSVC(penalty='l1',loss='squared_hinge',dual=False ,random_state=i,max_iter=100000)\n",
    "        test_params2 = {'C':[0.01,0.05,0.1,0.5,1,5,10,50,100]}\n",
    "    \n",
    "        l1_svc_gs2 = GridSearchCV(estimator = l1_svc2, param_grid = test_params2,cv=5).\\\n",
    "        fit(locals() ['x_train_set'+str(j)],locals()['y_train_set'+str(j)])\n",
    "        pre_test = l1_svc_gs2.predict(X_test2)\n",
    "        test_f1 = f1_score(y_test2,pre_test,average='micro')\n",
    "        (locals() ['passive_error'+str(j)]).append(test_f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2f95aae0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9915254237288135"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for n in range(0,90):\n",
    "    locals() ['passive_error'+str(n)+'_average'] = np.average(locals() ['passive_error'+str(n)])\n",
    "passive_error80_average"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56784c35",
   "metadata": {},
   "source": [
    "#### Traina SVM with a pool of 10 randomly selected data points from the training set5 using linear kernel and L1 penalty. Select the parameters of the SVM with 5-fold cross validation. Choose the 10 closest data points in the training set to the hyperplane of the SVM6 and add them to the pool. Do not replace the samples back into the training set. Train a new SVM using the pool. Repeat this process until all training data is used. You will have 90 SVMs that were trained using 10, 20, 30,..., 900 data points and their 90 test errors. You have implemented active learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "87ece967",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "9 fits failed out of a total of 45.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "9 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_classes.py\", line 257, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 1143, in _fit_liblinear\n",
      "    raise ValueError(\n",
      "ValueError: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/jiadesong/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "for n in range(0,90):\n",
    "    locals() ['active_error'+str(n)]  = []\n",
    "        \n",
    "for i in Ran_num:\n",
    "    samp_X_train2 = X_train2.sample(frac=1,random_state=i)\n",
    "    samp_y_train2 = y_train2.sample(frac=1,random_state=i)\n",
    "    selected_x = samp_X_train2.iloc[:10]\n",
    "    selected_y = samp_y_train2.iloc[:10]\n",
    "    samp_X_train2 = samp_X_train2.drop(selected_x.index)\n",
    "    samp_y_train2 = samp_y_train2.drop(selected_y.index)\n",
    "    \n",
    "    update_X_train2 = selected_x\n",
    "    update_y_train2 = selected_y\n",
    "\n",
    "    for j in range(0,90):\n",
    "        \n",
    "        l1_svc = LinearSVC(penalty='l1',loss='squared_hinge',dual=False ,random_state=i,max_iter=1000000)\n",
    "        test_params2 = {'C':[0.01,0.05,0.1,0.5,1,5,10,50,100]}\n",
    "    \n",
    "        l1_svc_gs2 = GridSearchCV(estimator = l1_svc2, param_grid = test_params2,cv=5).\\\n",
    "        fit(update_X_train2,update_y_train2)\n",
    "        \n",
    "        if j < 89:\n",
    "            closest_10 = np.argsort((abs(l1_svc_gs2.decision_function(samp_X_train2))))[:10]\n",
    "            selected_x = samp_X_train2.iloc[closest_10]\n",
    "            selected_y = samp_y_train2.iloc[closest_10]\n",
    "\n",
    "            samp_X_train2 = samp_X_train2.drop(selected_x.index)\n",
    "            samp_y_train2 = samp_y_train2.drop(selected_y.index)\n",
    "\n",
    "            update_X_train2 = pd.concat([update_X_train2, selected_x])\n",
    "            update_y_train2 = pd.concat([update_y_train2, selected_y])\n",
    "        \n",
    "        pre_test = l1_svc_gs2.predict(X_test2)\n",
    "        test_f1 = f1_score(y_test2,pre_test,average='micro')\n",
    "        (locals() ['active_error'+str(j)]).append(test_f1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c518460c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9877824858757059"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for n in range(0,90):\n",
    "    locals() ['active_error'+str(n)+'_average'] = np.average(locals() ['active_error'+str(n)])\n",
    "active_error80_average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6632f3f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9425141242937854"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "active_error1_average"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ce77b4",
   "metadata": {},
   "source": [
    "### (c) Average the 50 test errors for each of the incrementally trained 90 SVMs in 2(b)i and 2(b)ii. By doing so, you are performing a Monte Carlo simulation. Plot average test error versus number of training instances for both active and passive learners on the same figure and report your conclusions. Here, you are actually obtaining a learning curve by Monte-Carlo simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d41dc30a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
       "       34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
       "       51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67,\n",
       "       68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84,\n",
       "       85, 86, 87, 88, 89])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(range(0,90))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b8c5ae72",
   "metadata": {},
   "outputs": [],
   "source": [
    "act_array = []\n",
    "for i in range(0,90):\n",
    "    act_array.append(1-(locals() ['active_error'+str(i)+'_average']))\n",
    "    \n",
    "pas_array = []\n",
    "for i in range(0,90):\n",
    "    pas_array.append(1-(locals() ['passive_error'+str(i)+'_average']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "64b66e72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Test Error')"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.array(range(0,90)), act_array, 'r', label = 'Active Learning Error')\n",
    "plt.plot(np.array(range(0,90)), pas_array, 'b', label = 'Passive Learning Error')\n",
    "plt.title('Passive Learning vs Active Learning')\n",
    "plt.legend() \n",
    "plt.xlabel('Training data Selection Process')\n",
    "plt.ylabel('Test Error')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0e9c22",
   "metadata": {},
   "source": [
    "    Active learning has a faster error decreasing process than Passive learning but has a worse performance (higher error) at the final situation (select all data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2ac8cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
