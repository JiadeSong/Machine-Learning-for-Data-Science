{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa612bfa",
   "metadata": {},
   "source": [
    "<center><h1>DSCI-552 Final_Project</h1></center>\n",
    "<br>\n",
    "<center><font size=\"4\">Name: Jiade Song    GitHubID: JiadeSong     USCID: 9019610285 </font></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42cec426",
   "metadata": {},
   "source": [
    "<center><font size=\"4\">1. Text Classification</font></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd6efcce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import string\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import keras\n",
    "from tensorflow.keras.layers import Embedding,Input,Dense,Flatten,Dropout,Conv1D,MaxPooling1D,LSTM\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4788c6a",
   "metadata": {},
   "source": [
    "### (b) Data Exploration and Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36d4b13",
   "metadata": {},
   "source": [
    "#### i. You can use binary encoding for the sentiments , i.e y = 1 for positive sentiments and y = −1 for negative sentiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ebbbb8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_file_path = r'../../Data/neg'\n",
    "pos_file_path = r'../../Data/pos'\n",
    "neg_name_arr = []\n",
    "pos_name_arr = []\n",
    "neg_text_arr = []\n",
    "pos_text_arr = []\n",
    "neg_cla_arr = []\n",
    "pos_cla_arr = []\n",
    "\n",
    "all_neg_files = glob.glob(neg_file_path + \"/*.txt\")\n",
    "all_pos_files = glob.glob(pos_file_path + \"/*.txt\")\n",
    "for f in all_neg_files:\n",
    "    neg_name_arr.append(f[(f.find('neg')+4):-4])\n",
    "    a = open(f, \"r\")\n",
    "    neg_text_arr.append(a.read())\n",
    "    neg_cla_arr.append(0)\n",
    "    \n",
    "    \n",
    "for f in all_pos_files:\n",
    "    pos_name_arr.append(f[(f.find('pos')+4):-4])\n",
    "    a = open(f, \"r\")\n",
    "    pos_text_arr.append(a.read())\n",
    "    pos_cla_arr.append(1)\n",
    "    \n",
    "name_arr = np.concatenate((neg_name_arr, pos_name_arr))\n",
    "text_arr = np.concatenate((neg_text_arr, pos_text_arr))\n",
    "cla_arr = np.concatenate((neg_cla_arr, pos_cla_arr))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e87145",
   "metadata": {},
   "source": [
    "### Note: Here I modify the negative class to label as 0 which gives a better performance when training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e97d53b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cv676_22202</td>\n",
       "      <td>bad . bad . \\nbad . \\nthat one word seems to p...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cv839_22807</td>\n",
       "      <td>isn't it the ultimate sign of a movie's cinema...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cv155_7845</td>\n",
       "      <td>\" gordy \" is not a movie , it is a 90-minute-...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cv465_23401</td>\n",
       "      <td>disconnect the phone line . \\ndon't accept the...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cv398_17047</td>\n",
       "      <td>when robert forster found himself famous again...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>cv588_13008</td>\n",
       "      <td>one of the funniest carry on movies and the th...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>cv734_21568</td>\n",
       "      <td>i remember making a pact , right after `patch ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>cv491_12145</td>\n",
       "      <td>barely scrapping by playing at a nyc piano bar...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>cv647_13691</td>\n",
       "      <td>if the current trends of hollywood filmmaking ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>cv665_29538</td>\n",
       "      <td>capsule : the director of cure brings a weird ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             name                                               text  class\n",
       "0     cv676_22202  bad . bad . \\nbad . \\nthat one word seems to p...      0\n",
       "1     cv839_22807  isn't it the ultimate sign of a movie's cinema...      0\n",
       "2      cv155_7845   \" gordy \" is not a movie , it is a 90-minute-...      0\n",
       "3     cv465_23401  disconnect the phone line . \\ndon't accept the...      0\n",
       "4     cv398_17047  when robert forster found himself famous again...      0\n",
       "...           ...                                                ...    ...\n",
       "1995  cv588_13008  one of the funniest carry on movies and the th...      1\n",
       "1996  cv734_21568  i remember making a pact , right after `patch ...      1\n",
       "1997  cv491_12145  barely scrapping by playing at a nyc piano bar...      1\n",
       "1998  cv647_13691  if the current trends of hollywood filmmaking ...      1\n",
       "1999  cv665_29538  capsule : the director of cure brings a weird ...      1\n",
       "\n",
       "[2000 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'name':name_arr, 'text':text_arr, 'class':cla_arr})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00000d5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'isn\\'t it the ultimate sign of a movie\\'s cinematic ineptitude when you can\\'t think of much to say about it other than \" it sucks \" ? \\none of the first official year 2000 releases , supernova is such a movie . \\ni can\\'t seem to get past one-word adjectives with this one , although \" boring , \" \" stupid \" and \" absurd \" doesn\\'t amount to much of a review . \\na shame . \\ni would have been able to save myself the chore of desperately trying to elaborate . \\nbut c\\'est la vie . \\nhere goes nothing . \\ni\\'ll keep it short . \\ni suppose the first bad omen for supernova came when director walter hill ( 48 hours ) removed his name from the movie , requesting that it be replaced with the pseudonym thomas lee . \\nthe film\\'s fate was sealed in many minds when struggling studio mgm declined to screen it for the press , an event usually signifying a studio\\'s lack of confidence in a particular movie . \\nhill\\'s and mgm\\'s actions were prudent . \\nwhen the captain of medical space vessel nightingale dies in a tragic hyperjump accident , a reformed drug addict who is also the first officer , for some reason ( james spader ) is forced to take command . \\nthe ship picks up a distress call from a nearby planet and , on arrival , picks up one survivor from an apparent accident in an abandoned mining colony . \\none of the crew members ( angela bassett ) knows this passenger , who is played by peter facinelli , and has some bad feelings about it -- and we all know what that means . \\nthis intergalactic hitchhiker is carrying some mysterious cargo -- a jellylike substance the purpose of which is unknown , though it seems to bring some form of pleasure to whoever touches it . \\nanother one of the crew members experiences this first hand ; after spending a few minutes partially inside this glob of goo , he does some impressive handstand pushups . \\nevidently , touching this enigmatic egg-shaped thingie makes you younger and stronger . \\nhow ? \\nwhy ? \\nthe movie never bothers to explain . \\nsoon enough though , spader and bassett are running around the ship like mad , being chased by the all-of-a-sudden-superhuman facinelli . \\nto be honest , i don\\'t even remember exactly why . \\ni just remember that i didn\\'t care . \\nsupernova\\'s plot suggested some more or less interesting ideas , such as the ball of goo being an intergalactic time bomb , but they are all dropped before they have a chance to develop into anything truly intriguing . \\nin fact , everything is dropped just so the actors can have some fun running around what looks like an elaborate set . \\nwell , the effects are good , though there\\'s hardly a studio movie with bad special effects these days so i\\'m not sure whether that\\'s so remarkable an accomplishment . \\nthe performances are hardly worth talking about . \\ni\\'m not even sure i can call what\\'s here \" performances , \" though angela bassett sure is good at giving people the finger . \\njames spader is not a bad actor , but he proves to be one of the blandest action stars i\\'ve seen in a while , mostly because he isn\\'t given a character with a personality . \\nthe action scenes are just as bland , since they\\'re pretty much just rehashes of action elements that weren\\'t particularly entertaining the first time around . \\nand since the action scenes are everything to this movie , it\\'s pretty much dead in the water . \\nand for the life of me , i can\\'t figure out why it\\'s called supernova . \\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2d5152",
   "metadata": {},
   "source": [
    "#### ii. The data are pretty clean. Remove the punctuation and numbers from the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "905b7586",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c2/55q5nzv51vz59zgdv6yql13m0000gn/T/ipykernel_29774/3025309946.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['text'][i] = no_number\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cv676_22202</td>\n",
       "      <td>bad  bad  bad  that one word seems to pretty m...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cv839_22807</td>\n",
       "      <td>isnt it the ultimate sign of a movies cinemati...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cv155_7845</td>\n",
       "      <td>gordy  is not a movie  it is a minutelong  s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cv465_23401</td>\n",
       "      <td>disconnect the phone line  dont accept the cha...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cv398_17047</td>\n",
       "      <td>when robert forster found himself famous again...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>cv588_13008</td>\n",
       "      <td>one of the funniest carry on movies and the th...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>cv734_21568</td>\n",
       "      <td>i remember making a pact  right after patch ad...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>cv491_12145</td>\n",
       "      <td>barely scrapping by playing at a nyc piano bar...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>cv647_13691</td>\n",
       "      <td>if the current trends of hollywood filmmaking ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>cv665_29538</td>\n",
       "      <td>capsule  the director of cure brings a weird a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             name                                               text  class\n",
       "0     cv676_22202  bad  bad  bad  that one word seems to pretty m...      0\n",
       "1     cv839_22807  isnt it the ultimate sign of a movies cinemati...      0\n",
       "2      cv155_7845    gordy  is not a movie  it is a minutelong  s...      0\n",
       "3     cv465_23401  disconnect the phone line  dont accept the cha...      0\n",
       "4     cv398_17047  when robert forster found himself famous again...      0\n",
       "...           ...                                                ...    ...\n",
       "1995  cv588_13008  one of the funniest carry on movies and the th...      1\n",
       "1996  cv734_21568  i remember making a pact  right after patch ad...      1\n",
       "1997  cv491_12145  barely scrapping by playing at a nyc piano bar...      1\n",
       "1998  cv647_13691  if the current trends of hollywood filmmaking ...      1\n",
       "1999  cv665_29538  capsule  the director of cure brings a weird a...      1\n",
       "\n",
       "[2000 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(0,len(df)):\n",
    "    no_punc = df['text'][i].translate(str.maketrans('', '', string.punctuation))\n",
    "    no_new_line = no_punc.replace('\\n', '')\n",
    "    no_number = re.sub(r'\\d+', '', no_new_line)\n",
    "    df['text'][i] = no_number\n",
    "df\n",
    "#https://stackoverflow.com/questions/34293875/how-to-remove-punctuation-marks-\n",
    "#from-a-string-in-python-3-x-using-translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2b6aa40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'isnt it the ultimate sign of a movies cinematic ineptitude when you cant think of much to say about it other than  it sucks   one of the first official year  releases  supernova is such a movie  i cant seem to get past oneword adjectives with this one  although  boring    stupid  and  absurd  doesnt amount to much of a review  a shame  i would have been able to save myself the chore of desperately trying to elaborate  but cest la vie  here goes nothing  ill keep it short  i suppose the first bad omen for supernova came when director walter hill   hours  removed his name from the movie  requesting that it be replaced with the pseudonym thomas lee  the films fate was sealed in many minds when struggling studio mgm declined to screen it for the press  an event usually signifying a studios lack of confidence in a particular movie  hills and mgms actions were prudent  when the captain of medical space vessel nightingale dies in a tragic hyperjump accident  a reformed drug addict who is also the first officer  for some reason  james spader  is forced to take command  the ship picks up a distress call from a nearby planet and  on arrival  picks up one survivor from an apparent accident in an abandoned mining colony  one of the crew members  angela bassett  knows this passenger  who is played by peter facinelli  and has some bad feelings about it  and we all know what that means  this intergalactic hitchhiker is carrying some mysterious cargo  a jellylike substance the purpose of which is unknown  though it seems to bring some form of pleasure to whoever touches it  another one of the crew members experiences this first hand  after spending a few minutes partially inside this glob of goo  he does some impressive handstand pushups  evidently  touching this enigmatic eggshaped thingie makes you younger and stronger  how  why  the movie never bothers to explain  soon enough though  spader and bassett are running around the ship like mad  being chased by the allofasuddensuperhuman facinelli  to be honest  i dont even remember exactly why  i just remember that i didnt care  supernovas plot suggested some more or less interesting ideas  such as the ball of goo being an intergalactic time bomb  but they are all dropped before they have a chance to develop into anything truly intriguing  in fact  everything is dropped just so the actors can have some fun running around what looks like an elaborate set  well  the effects are good  though theres hardly a studio movie with bad special effects these days so im not sure whether thats so remarkable an accomplishment  the performances are hardly worth talking about  im not even sure i can call whats here  performances   though angela bassett sure is good at giving people the finger  james spader is not a bad actor  but he proves to be one of the blandest action stars ive seen in a while  mostly because he isnt given a character with a personality  the action scenes are just as bland  since theyre pretty much just rehashes of action elements that werent particularly entertaining the first time around  and since the action scenes are everything to this movie  its pretty much dead in the water  and for the life of me  i cant figure out why its called supernova  '"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835c6c66",
   "metadata": {},
   "source": [
    "#### iii. The name of each text file starts with cv number. Use text files 0-699 in each class for training and 700-999 for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "94c93729",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame({'name':[],'text':[],'class':[]})\n",
    "test_df = pd.DataFrame({'name':[],'text':[],'class':[]})\n",
    "for i in range(0,len(df)):\n",
    "    if int(df['name'][i][2:5]) <=  699:\n",
    "        train_df.loc[len(train_df.index)] = df.iloc[i]\n",
    "    else:\n",
    "        test_df.loc[len(test_df.index)] = df.iloc[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d431e8d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cv676_22202</td>\n",
       "      <td>bad  bad  bad  that one word seems to pretty m...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cv155_7845</td>\n",
       "      <td>gordy  is not a movie  it is a minutelong  s...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cv465_23401</td>\n",
       "      <td>disconnect the phone line  dont accept the cha...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cv398_17047</td>\n",
       "      <td>when robert forster found himself famous again...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cv206_15893</td>\n",
       "      <td>this is my first review that i post to this ne...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1395</th>\n",
       "      <td>cv033_24444</td>\n",
       "      <td>in wonder boys michael douglas plays an aged w...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1396</th>\n",
       "      <td>cv588_13008</td>\n",
       "      <td>one of the funniest carry on movies and the th...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1397</th>\n",
       "      <td>cv491_12145</td>\n",
       "      <td>barely scrapping by playing at a nyc piano bar...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1398</th>\n",
       "      <td>cv647_13691</td>\n",
       "      <td>if the current trends of hollywood filmmaking ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1399</th>\n",
       "      <td>cv665_29538</td>\n",
       "      <td>capsule  the director of cure brings a weird a...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1400 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             name                                               text  class\n",
       "0     cv676_22202  bad  bad  bad  that one word seems to pretty m...    0.0\n",
       "1      cv155_7845    gordy  is not a movie  it is a minutelong  s...    0.0\n",
       "2     cv465_23401  disconnect the phone line  dont accept the cha...    0.0\n",
       "3     cv398_17047  when robert forster found himself famous again...    0.0\n",
       "4     cv206_15893  this is my first review that i post to this ne...    0.0\n",
       "...           ...                                                ...    ...\n",
       "1395  cv033_24444  in wonder boys michael douglas plays an aged w...    1.0\n",
       "1396  cv588_13008  one of the funniest carry on movies and the th...    1.0\n",
       "1397  cv491_12145  barely scrapping by playing at a nyc piano bar...    1.0\n",
       "1398  cv647_13691  if the current trends of hollywood filmmaking ...    1.0\n",
       "1399  cv665_29538  capsule  the director of cure brings a weird a...    1.0\n",
       "\n",
       "[1400 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67006d37",
   "metadata": {},
   "source": [
    "#### iv. Count the number of unique words in the whole dataset (train + test) and print it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7762a61e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46830"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = set()\n",
    "df['text'].str.lower().str.split().apply(results.update)\n",
    "len(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6070c1",
   "metadata": {},
   "source": [
    "#### Answer: Number of unique words is 46830."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57642ec",
   "metadata": {},
   "source": [
    "#### v. Calculate the average review length and the standard deviation of review lengths. Report the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "55a4b825",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The row number of training set is: 1400\n",
      "The average review length of training text is: 641.4178571428571\n",
      "The review length std of training text is: 285.0965181848464\n",
      "---------------------------------------------------------------\n",
      "The row number of testing set is: 600\n",
      "The average review length of testing text is: 651.21\n",
      "The review length std of testing text is: 284.5896096135627\n",
      "---------------------------------------------------------------\n",
      "The average review length of whole text set is: 644.3555\n",
      "The review length std of whole text set is: 284.97987142910637\n"
     ]
    }
   ],
   "source": [
    "train_len = []\n",
    "print('The row number of training set is: ' + str(len(train_df)))\n",
    "for i in range(0,len(train_df)):\n",
    "    result_len = len(train_df['text'][i].split())\n",
    "    train_len.append(result_len)\n",
    "\n",
    "print('The average review length of training text is: ' + str(np.mean(train_len)))\n",
    "print('The review length std of training text is: ' + str(np.std(train_len)))\n",
    "print('---------------------------------------------------------------')\n",
    "test_len = []\n",
    "print('The row number of testing set is: ' + str(len(test_df)))\n",
    "for i in range(0,len(test_df)):\n",
    "    result_len = len(test_df['text'][i].split())\n",
    "    test_len.append(result_len)\n",
    "    \n",
    "print('The average review length of testing text is: ' + str(np.mean(test_len)))\n",
    "print('The review length std of testing text is: ' + str(np.std(test_len)))\n",
    "print('---------------------------------------------------------------')\n",
    "print('The average review length of whole text set is: ' + str(((np.mean(test_len))\\\n",
    "                                                                *600+(np.mean(train_len))*1400)/2000))\n",
    "all_len = train_len+test_len\n",
    "print('The review length std of whole text set is: ' + str(np.std(all_len)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f545de83",
   "metadata": {},
   "source": [
    "#### vi. Plot the histogram of review lengths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0814d917",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(train_len, density=False, bins=30)\n",
    "plt.ylabel('Number in each cell')\n",
    "plt.xlabel('Number of words')\n",
    "plt.title('Training Data');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "14e979c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(test_len, density=False, bins=30)\n",
    "plt.ylabel('Number in each cell')\n",
    "plt.xlabel('Number of words')\n",
    "plt.title('Testing Data');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3498516d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(all_len, density=False, bins=30)\n",
    "plt.ylabel('Number in each cell')\n",
    "plt.xlabel('Number of words')\n",
    "plt.title('All Data');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2202e55b",
   "metadata": {},
   "source": [
    "#### vii. To represent each text (= data point), there are many ways. In NLP/Deep Learning terminology, this task is called tokenization. It is common to represent text using popularity/ rank of words in text. The most common word in the text will be represented as 1, the second most common word will be represented as 2, etc. Tokenize each text document using this method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "095b81c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tok  = Tokenizer(num_words = 5001)\n",
    "\n",
    "tok.fit_on_texts(train_df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "035d9d7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The rank of words {'the': 1, 'a': 2, 'and': 3, 'of': 4, 'to': 5, 'is': 6, 'in': 7, 'that': 8, 'it': 9, 'as': 10, 'with': 11, 'for': 12, 'his': 13, 'this': 14, 'film': 15, 'but': 16, 'he': 17, 'i': 18, 'on': 19, 'are': 20, 'by': 21, 'its': 22, 'be': 23, 'an': 24, 'one': 25, 'not': 26, 'who': 27, 'movie': 28, 'at': 29, 'was': 30}\n"
     ]
    }
   ],
   "source": [
    "print(\"The rank of words\",dict(list(tok.word_index.items())[:30]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "115d32f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       bad  bad  bad  that one word seems to pretty m...\n",
       "1         gordy  is not a movie  it is a minutelong  s...\n",
       "2       disconnect the phone line  dont accept the cha...\n",
       "3       when robert forster found himself famous again...\n",
       "4       this is my first review that i post to this ne...\n",
       "                              ...                        \n",
       "1395    in wonder boys michael douglas plays an aged w...\n",
       "1396    one of the funniest carry on movies and the th...\n",
       "1397    barely scrapping by playing at a nyc piano bar...\n",
       "1398    if the current trends of hollywood filmmaking ...\n",
       "1399    capsule  the director of cure brings a weird a...\n",
       "Name: text, Length: 1400, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4eea93c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_train = tok.texts_to_sequences(train_df['text'])\n",
    "tokenized_test = tok.texts_to_sequences(test_df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6b417811",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "      <th>token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cv839_22807</td>\n",
       "      <td>isnt it the ultimate sign of a movies cinemati...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[170, 9, 1, 1779, 1646, 4, 2, 107, 1120, 43, 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cv756_23676</td>\n",
       "      <td>jet li busted onto the american action movie s...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[2816, 2768, 1218, 1, 249, 131, 28, 103, 43, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cv823_17055</td>\n",
       "      <td>starring shawnee smith  donovan leitch  ricky ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[724, 708, 3000, 431, 2673, 1153, 1, 6, 1, 161...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cv747_18189</td>\n",
       "      <td>in s  many european intellectuals  especially ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[7, 125, 116, 296, 142, 19, 1, 317, 894, 1347,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cv948_25870</td>\n",
       "      <td>and just when you thought joblo was getting a ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[3, 50, 43, 34, 347, 3955, 30, 334, 2, 92, 325...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>cv736_23670</td>\n",
       "      <td>the premise of the new teentargeted horror fil...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[1, 643, 4, 1, 114, 320, 15, 349, 2601, 2349, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>cv873_18636</td>\n",
       "      <td>in roger michells romantic comedy notting hill...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[7, 1542, 555, 181, 1522, 786, 1963, 605, 2, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>cv957_8737</td>\n",
       "      <td>capsule  the best place to start if youre a ja...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[2436, 1, 108, 233, 5, 452, 51, 401, 2, 488, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>cv804_10862</td>\n",
       "      <td>satirical films usually fall into one of two c...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[3855, 66, 624, 585, 53, 25, 4, 80, 1723, 99, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>cv734_21568</td>\n",
       "      <td>i remember making a pact  right after patch ad...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[18, 712, 263, 2, 184, 82, 1459, 1554, 5, 26, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>600 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            name                                               text  class  \\\n",
       "0    cv839_22807  isnt it the ultimate sign of a movies cinemati...    0.0   \n",
       "1    cv756_23676  jet li busted onto the american action movie s...    0.0   \n",
       "2    cv823_17055  starring shawnee smith  donovan leitch  ricky ...    0.0   \n",
       "3    cv747_18189  in s  many european intellectuals  especially ...    0.0   \n",
       "4    cv948_25870  and just when you thought joblo was getting a ...    0.0   \n",
       "..           ...                                                ...    ...   \n",
       "595  cv736_23670  the premise of the new teentargeted horror fil...    1.0   \n",
       "596  cv873_18636  in roger michells romantic comedy notting hill...    1.0   \n",
       "597   cv957_8737  capsule  the best place to start if youre a ja...    1.0   \n",
       "598  cv804_10862  satirical films usually fall into one of two c...    1.0   \n",
       "599  cv734_21568  i remember making a pact  right after patch ad...    1.0   \n",
       "\n",
       "                                                 token  \n",
       "0    [170, 9, 1, 1779, 1646, 4, 2, 107, 1120, 43, 3...  \n",
       "1    [2816, 2768, 1218, 1, 249, 131, 28, 103, 43, 1...  \n",
       "2    [724, 708, 3000, 431, 2673, 1153, 1, 6, 1, 161...  \n",
       "3    [7, 125, 116, 296, 142, 19, 1, 317, 894, 1347,...  \n",
       "4    [3, 50, 43, 34, 347, 3955, 30, 334, 2, 92, 325...  \n",
       "..                                                 ...  \n",
       "595  [1, 643, 4, 1, 114, 320, 15, 349, 2601, 2349, ...  \n",
       "596  [7, 1542, 555, 181, 1522, 786, 1963, 605, 2, 2...  \n",
       "597  [2436, 1, 108, 233, 5, 452, 51, 401, 2, 488, 1...  \n",
       "598  [3855, 66, 624, 585, 53, 25, 4, 80, 1723, 99, ...  \n",
       "599  [18, 712, 263, 2, 184, 82, 1459, 1554, 5, 26, ...  \n",
       "\n",
       "[600 rows x 4 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['token'] = tokenized_train\n",
    "test_df['token'] = tokenized_test\n",
    "test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee883fe8",
   "metadata": {},
   "source": [
    "#### viii. Select a review length L that 70% of the reviews have a length below it. If you feel more adventurous, set the threshold to 90%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f18b7c33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "730.3"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L = np.percentile(train_len, 70)\n",
    "L"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1eddfc",
   "metadata": {},
   "source": [
    "Answer: the 70% of the length is 730. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e60fd65f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The row number of training set is: 1400\n"
     ]
    }
   ],
   "source": [
    "train_len = []\n",
    "train_token = []\n",
    "Selected_len = []\n",
    "Selected_name = []\n",
    "Selected_text = []\n",
    "Selected_class = []\n",
    "Selected_token = []\n",
    "print('The row number of training set is: ' + str(len(train_df)))\n",
    "for i in range(0,len(train_df)):\n",
    "    result_len = len(train_df['text'][i].split())\n",
    "    if result_len <= L:\n",
    "        Selected_len.append(result_len)\n",
    "        Selected_text.append(train_df['text'][i])\n",
    "        Selected_name.append(train_df['name'][i])\n",
    "        Selected_class.append(train_df['class'][i])\n",
    "        Selected_token.append(train_df['token'][i])\n",
    "    train_len.append(result_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6cf0658e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "      <th>token</th>\n",
       "      <th>len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cv155_7845</td>\n",
       "      <td>gordy  is not a movie  it is a minutelong  s...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[6, 26, 2, 28, 9, 6, 2, 1177, 3, 2, 77, 104, 2...</td>\n",
       "      <td>480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cv465_23401</td>\n",
       "      <td>disconnect the phone line  dont accept the cha...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[1, 1720, 336, 119, 1771, 1, 4791, 75, 230, 34...</td>\n",
       "      <td>611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cv398_17047</td>\n",
       "      <td>when robert forster found himself famous again...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[43, 518, 4567, 369, 218, 1043, 211, 82, 3016,...</td>\n",
       "      <td>391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cv206_15893</td>\n",
       "      <td>this is my first review that i post to this ne...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[14, 6, 106, 78, 440, 8, 18, 4179, 5, 14, 3, 1...</td>\n",
       "      <td>437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cv037_19798</td>\n",
       "      <td>lake placid  marks yet another entry in the ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[2321, 2929, 238, 126, 2682, 7, 1, 271, 4, 8, ...</td>\n",
       "      <td>513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>975</th>\n",
       "      <td>cv254_6027</td>\n",
       "      <td>curdled is a deliciously dark and witty black ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[6, 2, 4901, 409, 3, 1366, 301, 181, 16, 22, 1...</td>\n",
       "      <td>636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>976</th>\n",
       "      <td>cv576_14094</td>\n",
       "      <td>as fairy tales go  cinderella has to be one of...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[10, 2421, 3042, 127, 33, 5, 23, 25, 4, 1, 63,...</td>\n",
       "      <td>561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>977</th>\n",
       "      <td>cv588_13008</td>\n",
       "      <td>one of the funniest carry on movies and the th...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[25, 4, 1, 2233, 1022, 19, 107, 3, 1, 772, 11,...</td>\n",
       "      <td>439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>978</th>\n",
       "      <td>cv491_12145</td>\n",
       "      <td>barely scrapping by playing at a nyc piano bar...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[1263, 21, 354, 29, 2, 3615, 1933, 1237, 5, 13...</td>\n",
       "      <td>354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>979</th>\n",
       "      <td>cv665_29538</td>\n",
       "      <td>capsule  the director of cure brings a weird a...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[2436, 1, 133, 4, 4638, 714, 2, 1461, 3, 77, 1...</td>\n",
       "      <td>645</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>980 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            name                                               text  class  \\\n",
       "0     cv155_7845    gordy  is not a movie  it is a minutelong  s...    0.0   \n",
       "1    cv465_23401  disconnect the phone line  dont accept the cha...    0.0   \n",
       "2    cv398_17047  when robert forster found himself famous again...    0.0   \n",
       "3    cv206_15893  this is my first review that i post to this ne...    0.0   \n",
       "4    cv037_19798    lake placid  marks yet another entry in the ...    0.0   \n",
       "..           ...                                                ...    ...   \n",
       "975   cv254_6027  curdled is a deliciously dark and witty black ...    1.0   \n",
       "976  cv576_14094  as fairy tales go  cinderella has to be one of...    1.0   \n",
       "977  cv588_13008  one of the funniest carry on movies and the th...    1.0   \n",
       "978  cv491_12145  barely scrapping by playing at a nyc piano bar...    1.0   \n",
       "979  cv665_29538  capsule  the director of cure brings a weird a...    1.0   \n",
       "\n",
       "                                                 token  len  \n",
       "0    [6, 26, 2, 28, 9, 6, 2, 1177, 3, 2, 77, 104, 2...  480  \n",
       "1    [1, 1720, 336, 119, 1771, 1, 4791, 75, 230, 34...  611  \n",
       "2    [43, 518, 4567, 369, 218, 1043, 211, 82, 3016,...  391  \n",
       "3    [14, 6, 106, 78, 440, 8, 18, 4179, 5, 14, 3, 1...  437  \n",
       "4    [2321, 2929, 238, 126, 2682, 7, 1, 271, 4, 8, ...  513  \n",
       "..                                                 ...  ...  \n",
       "975  [6, 2, 4901, 409, 3, 1366, 301, 181, 16, 22, 1...  636  \n",
       "976  [10, 2421, 3042, 127, 33, 5, 23, 25, 4, 1, 63,...  561  \n",
       "977  [25, 4, 1, 2233, 1022, 19, 107, 3, 1, 772, 11,...  439  \n",
       "978  [1263, 21, 354, 29, 2, 3615, 1933, 1237, 5, 13...  354  \n",
       "979  [2436, 1, 133, 4, 4638, 714, 2, 1461, 3, 77, 1...  645  \n",
       "\n",
       "[980 rows x 5 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Selected_train_df = pd.DataFrame({'name':Selected_name, 'text':Selected_text, 'class':Selected_class,\\\n",
    "                                  'token':Selected_token,'len':Selected_len})\n",
    "Selected_train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27558a53",
   "metadata": {},
   "source": [
    "##### the df table above is the text length larger than 730 (980 rows, 70 percentile), which is not the whole data to train. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d7610d",
   "metadata": {},
   "source": [
    "#### ix. Truncate reviews longer than L words and zero-pad reviews shorter than L so that all texts (= data points) are of length L."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bad19b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pad = pad_sequences(train_df['token'], maxlen = 730)\n",
    "test_pad = pad_sequences(test_df['token'], maxlen = 730)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "16c1b8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cut_tokens = []\n",
    "for i in range(0,len(train_pad)):\n",
    "    cut_tokens.append(train_pad[i])\n",
    "\n",
    "cut_tokens2 = []\n",
    "for i in range(0,len(test_pad)):\n",
    "    cut_tokens2.append(test_pad[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "235b51f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "      <th>token</th>\n",
       "      <th>cut_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cv839_22807</td>\n",
       "      <td>isnt it the ultimate sign of a movies cinemati...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[170, 9, 1, 1779, 1646, 4, 2, 107, 1120, 43, 3...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cv756_23676</td>\n",
       "      <td>jet li busted onto the american action movie s...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[2816, 2768, 1218, 1, 249, 131, 28, 103, 43, 1...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cv823_17055</td>\n",
       "      <td>starring shawnee smith  donovan leitch  ricky ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[724, 708, 3000, 431, 2673, 1153, 1, 6, 1, 161...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cv747_18189</td>\n",
       "      <td>in s  many european intellectuals  especially ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[7, 125, 116, 296, 142, 19, 1, 317, 894, 1347,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cv948_25870</td>\n",
       "      <td>and just when you thought joblo was getting a ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[3, 50, 43, 34, 347, 3955, 30, 334, 2, 92, 325...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>cv736_23670</td>\n",
       "      <td>the premise of the new teentargeted horror fil...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[1, 643, 4, 1, 114, 320, 15, 349, 2601, 2349, ...</td>\n",
       "      <td>[8, 91, 989, 139, 52, 65, 53, 2, 2997, 4, 732,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>cv873_18636</td>\n",
       "      <td>in roger michells romantic comedy notting hill...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[7, 1542, 555, 181, 1522, 786, 1963, 605, 2, 2...</td>\n",
       "      <td>[279, 1, 78, 951, 224, 4, 15, 3, 44, 109, 82, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>cv957_8737</td>\n",
       "      <td>capsule  the best place to start if youre a ja...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[2436, 1, 108, 233, 5, 452, 51, 401, 2, 488, 1...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>cv804_10862</td>\n",
       "      <td>satirical films usually fall into one of two c...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[3855, 66, 624, 585, 53, 25, 4, 80, 1723, 99, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>cv734_21568</td>\n",
       "      <td>i remember making a pact  right after patch ad...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[18, 712, 263, 2, 184, 82, 1459, 1554, 5, 26, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>600 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            name                                               text  class  \\\n",
       "0    cv839_22807  isnt it the ultimate sign of a movies cinemati...    0.0   \n",
       "1    cv756_23676  jet li busted onto the american action movie s...    0.0   \n",
       "2    cv823_17055  starring shawnee smith  donovan leitch  ricky ...    0.0   \n",
       "3    cv747_18189  in s  many european intellectuals  especially ...    0.0   \n",
       "4    cv948_25870  and just when you thought joblo was getting a ...    0.0   \n",
       "..           ...                                                ...    ...   \n",
       "595  cv736_23670  the premise of the new teentargeted horror fil...    1.0   \n",
       "596  cv873_18636  in roger michells romantic comedy notting hill...    1.0   \n",
       "597   cv957_8737  capsule  the best place to start if youre a ja...    1.0   \n",
       "598  cv804_10862  satirical films usually fall into one of two c...    1.0   \n",
       "599  cv734_21568  i remember making a pact  right after patch ad...    1.0   \n",
       "\n",
       "                                                 token  \\\n",
       "0    [170, 9, 1, 1779, 1646, 4, 2, 107, 1120, 43, 3...   \n",
       "1    [2816, 2768, 1218, 1, 249, 131, 28, 103, 43, 1...   \n",
       "2    [724, 708, 3000, 431, 2673, 1153, 1, 6, 1, 161...   \n",
       "3    [7, 125, 116, 296, 142, 19, 1, 317, 894, 1347,...   \n",
       "4    [3, 50, 43, 34, 347, 3955, 30, 334, 2, 92, 325...   \n",
       "..                                                 ...   \n",
       "595  [1, 643, 4, 1, 114, 320, 15, 349, 2601, 2349, ...   \n",
       "596  [7, 1542, 555, 181, 1522, 786, 1963, 605, 2, 2...   \n",
       "597  [2436, 1, 108, 233, 5, 452, 51, 401, 2, 488, 1...   \n",
       "598  [3855, 66, 624, 585, 53, 25, 4, 80, 1723, 99, ...   \n",
       "599  [18, 712, 263, 2, 184, 82, 1459, 1554, 5, 26, ...   \n",
       "\n",
       "                                            cut_tokens  \n",
       "0    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "3    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "4    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "..                                                 ...  \n",
       "595  [8, 91, 989, 139, 52, 65, 53, 2, 2997, 4, 732,...  \n",
       "596  [279, 1, 78, 951, 224, 4, 15, 3, 44, 109, 82, ...  \n",
       "597  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "598  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "599  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "\n",
       "[600 rows x 5 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['cut_tokens'] = cut_tokens\n",
    "test_df['cut_tokens'] = cut_tokens2\n",
    "test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57398c7d",
   "metadata": {},
   "source": [
    "### (c) Word Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc3283b",
   "metadata": {},
   "source": [
    "#### i. One can use tokenized text as inputs to a deep neural network. However, a recent breakthrough in NLP suggests that more sophisticated representations of text yield better results. These sophisticated representations are called word embeddings. “Word embedding is a term used for representation of words for text analysis, typically in the form of a real-valued vector that encodes the meaning of the word such that the words that are closer in the vector space are expected to be similar in meaning.”4. Most deep learning modules (including Keras) provide a convenient way to convert positive integer rep- resentations of words into a word embedding by an “Embedding layer.” The layer accepts arguments that define the mapping of words into embeddings, including the maximum number of expected words also called the vocabulary size (e.g. the largest integer value). The layer also allows you to specify the dimension for each word vector, called the “output dimension.” We would like to use a word embedding layer for this project. Assume that we are inter- ested in the top 5,000 words. This means that in each integer sequence that represents each document, we set to zero those integers that represent words that are not among the top 5,000 words in the document.5 If you feel more adventurous, use all the words that appear in this corpus. Choose the length of the embedding vector for each word to be 32. Hence, each document is represented as a 32 × 500 matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cc4a52b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-11 02:56:14.377277: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a6a0ace2",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = Embedding(5001, 32, input_length=730)\n",
    "model.add(embedding_layer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "007de574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 730, 32)           160032    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 160,032\n",
      "Trainable params: 160,032\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ad3d9e",
   "metadata": {},
   "source": [
    "#### ii. Flatten the matrix of each document to a vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "aa08fdfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be22a3dd",
   "metadata": {},
   "source": [
    "### (d) Multi-Layer Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b58454",
   "metadata": {},
   "source": [
    "#### i. Train a MLP with three (dense) hidden layers each of which has 50 ReLUs and one output layer with a single sigmoid neuron. Use a dropout rate of 20% for the first layer and 50% for the other layers. Use ADAM optimizer and binary cross entropy loss (which is equivalent to having a softmax in the output). To avoid overfitting, just set the number of epochs as 2. Use a batch size of 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "79aab4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(50,activation='ReLU'))\n",
    "model.add(Dropout(0.20))\n",
    "model.add(Dense(50,activation='ReLU'))\n",
    "model.add(Dropout(0.50))\n",
    "model.add(Dense(50,activation='ReLU'))\n",
    "model.add(Dropout(0.50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f138b650",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1c729d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=0.001),loss='binary_crossentropy',metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "521686af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input1=Input(shape=(len(train_df),730),dtype='float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d42fe479",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 730, 32)           160032    \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 23360)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 50)                1168050   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 50)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 50)                2550      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 50)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 50)                2550      \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 50)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,333,233\n",
      "Trainable params: 1,333,233\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ae17db93",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   1,   15,    9, ..., 4174,   11, 1842],\n",
       "       [   0,    0,    0, ...,   81,   71, 1575],\n",
       "       [   0,    0,    0, ...,   31,    1,  486],\n",
       "       ...,\n",
       "       [   0,    0,    0, ...,   92,   89,  394],\n",
       "       [   0,    0,    0, ..., 1634,    7,    9],\n",
       "       [   0,    0,    0, ...,    1,    5, 1628]], dtype=int32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "28affe6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.49939263],\n",
       "       [0.49669516],\n",
       "       [0.4982751 ],\n",
       "       ...,\n",
       "       [0.49682048],\n",
       "       [0.49310458],\n",
       "       [0.49402043]], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(train_pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c2d5d8f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "140/140 [==============================] - 2s 7ms/step - loss: 0.6984 - acc: 0.5057\n",
      "Epoch 2/2\n",
      "140/140 [==============================] - 1s 7ms/step - loss: 0.6609 - acc: 0.5907\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fdfd730ad30>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_pad, train_df['class'], epochs=2, batch_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88911da3",
   "metadata": {},
   "source": [
    "#### ii. Report the train and test accuracies of this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4974248d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 0s 2ms/step - loss: 0.6701 - acc: 0.5883\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6700639724731445, 0.5883333086967468]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_pad,  test_df['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "716c323c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - 0s 3ms/step - loss: 0.4339 - acc: 0.9136\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.43386614322662354, 0.9135714173316956]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(train_pad,  train_df['class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bcffacf",
   "metadata": {},
   "source": [
    "#### The train accuracy is 0.80 (mostly) and test accuracy is 0.55 (mostly) for 2 epochs but not stable.\n",
    "#### The train accuracy is 0.99 and test accuracy is 0.7100 for 3 epochs. After 3 epochs, the test accuracy decreases. (Overfitting)\n",
    "#### With number of epochsof 5 the training acc decreases to 64%\n",
    "#### With number of epochs larger than 10 the training acc decreases to 63%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e77a01",
   "metadata": {},
   "source": [
    "### (e) One-Dimensional Convolutional Neural Network: \n",
    "#### Although CNNs are mainly used for image data, they can also be applied to text data, as text also has adjacency information. Keras supports one-dimensional convolutions and pooling by the Conv1D and MaxPooling1D classes respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c508d8",
   "metadata": {},
   "source": [
    "#### i. After the embedding layer, insert a Conv1D layer. This convolutional layer has 32 feature maps , and each of the 32 kernels has size 3, i.e. reads embedded word representations 3 vector elements of the word embedding at a time. The convolutional layer is followed by a 1D max pooling layer with a length and stride of 2 that halves the size of the feature maps from the convolutional layer. The rest of the network is the same as the neural network above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "165ae8f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 730, 32)           160032    \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 728, 32)           3104      \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 364, 32)          0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 11648)             0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 50)                582450    \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 50)                0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 50)                2550      \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 50)                0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 50)                2550      \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 50)                0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 750,737\n",
      "Trainable params: 750,737\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "embedding_layer = Embedding(5001, 32, input_length=730)\n",
    "model.add(embedding_layer)\n",
    "model.add(Conv1D(32,3,input_shape=(None, 730, 32)))\n",
    "model.add(MaxPooling1D(pool_size = 2,strides = 2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(50,activation='ReLU'))\n",
    "model.add(Dropout(0.20))\n",
    "model.add(Dense(50,activation='ReLU'))\n",
    "model.add(Dropout(0.50))\n",
    "model.add(Dense(50,activation='ReLU'))\n",
    "model.add(Dropout(0.50))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['acc'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2490f639",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "140/140 [==============================] - 2s 12ms/step - loss: 0.7010 - acc: 0.5157\n",
      "Epoch 2/2\n",
      "140/140 [==============================] - 2s 12ms/step - loss: 0.6875 - acc: 0.5371\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fdfd7a615e0>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_pad, train_df['class'], epochs=2, batch_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "029ea4b6",
   "metadata": {},
   "source": [
    "#### ii. Report the train and test accuracies of this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "041b49c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - 0s 3ms/step - loss: 0.6223 - acc: 0.8093\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6223115921020508, 0.8092857003211975]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(train_pad,  train_df['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "949cf223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 0s 3ms/step - loss: 0.6805 - acc: 0.5883\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6805057525634766, 0.5883333086967468]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_pad,  test_df['class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff869be7",
   "metadata": {},
   "source": [
    "#### The train accuracy is 0.85 and test accuracy is 0.55 for 2 epochs (mostly, but not stable). \n",
    "#### The train accuracy is 0.9971 and test accuracy is 0.6800 for 4 epochs. \n",
    "#### The train accuracy is 1.0000 and test accuracy is 0.7700 for 10 epochs. \n",
    "#### The train accuracy is 1.0000 and test accuracy is 0.7983 for 25 epochs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8fc6d39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5d411114",
   "metadata": {},
   "source": [
    "### (f) Long Short-Term Memory Recurrent Neural Network:\n",
    "#### The structure of the LSTM we are going to use is shown in the following figure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3124520",
   "metadata": {},
   "source": [
    "#### i. Each word is represented to LSTM as a vector of 32 elements and the LSTM is followed by a dense layer of 256 ReLUs. Use a dropout rate of 0.2 for both LSTM and the dense layer. Train the model using 10-50 epochs and batch size of 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "676bee5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, 730, 32)           160032    \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 32)                8320      \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 256)               8448      \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 177,057\n",
      "Trainable params: 177,057\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "embedding_layer = Embedding(5001, 32, input_length=730)\n",
    "model.add(embedding_layer)\n",
    "\n",
    "# model.add(Flatten())\n",
    "model.add(LSTM(32))\n",
    "model.add(Dropout(0.20))\n",
    "model.add(Dense(256,activation='ReLU'))\n",
    "model.add(Dropout(0.20))\n",
    "\n",
    "\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['acc'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7c9aea8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "140/140 [==============================] - 20s 132ms/step - loss: 0.6908 - acc: 0.5286\n",
      "Epoch 2/20\n",
      "140/140 [==============================] - 17s 121ms/step - loss: 0.5243 - acc: 0.7693\n",
      "Epoch 3/20\n",
      "140/140 [==============================] - 17s 118ms/step - loss: 0.1848 - acc: 0.9343\n",
      "Epoch 4/20\n",
      "140/140 [==============================] - 19s 133ms/step - loss: 0.0863 - acc: 0.9714\n",
      "Epoch 5/20\n",
      "140/140 [==============================] - 17s 121ms/step - loss: 0.0614 - acc: 0.9807\n",
      "Epoch 6/20\n",
      "140/140 [==============================] - 16s 115ms/step - loss: 0.1321 - acc: 0.9536\n",
      "Epoch 7/20\n",
      "140/140 [==============================] - 16s 118ms/step - loss: 0.0203 - acc: 0.9921\n",
      "Epoch 8/20\n",
      "140/140 [==============================] - 17s 122ms/step - loss: 0.0061 - acc: 0.9979\n",
      "Epoch 9/20\n",
      "140/140 [==============================] - 17s 122ms/step - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 10/20\n",
      "140/140 [==============================] - 18s 128ms/step - loss: 4.9761e-04 - acc: 1.0000\n",
      "Epoch 11/20\n",
      "140/140 [==============================] - 16s 114ms/step - loss: 3.1217e-04 - acc: 1.0000\n",
      "Epoch 12/20\n",
      "140/140 [==============================] - 17s 120ms/step - loss: 2.3955e-04 - acc: 1.0000\n",
      "Epoch 13/20\n",
      "140/140 [==============================] - 19s 135ms/step - loss: 1.7533e-04 - acc: 1.0000\n",
      "Epoch 14/20\n",
      "140/140 [==============================] - 16s 117ms/step - loss: 1.4764e-04 - acc: 1.0000\n",
      "Epoch 15/20\n",
      "140/140 [==============================] - 17s 122ms/step - loss: 1.0511e-04 - acc: 1.0000\n",
      "Epoch 16/20\n",
      "140/140 [==============================] - 17s 120ms/step - loss: 8.6011e-05 - acc: 1.0000\n",
      "Epoch 17/20\n",
      "140/140 [==============================] - 17s 121ms/step - loss: 9.0687e-05 - acc: 1.0000\n",
      "Epoch 18/20\n",
      "140/140 [==============================] - 16s 111ms/step - loss: 6.3166e-05 - acc: 1.0000\n",
      "Epoch 19/20\n",
      "140/140 [==============================] - 15s 104ms/step - loss: 6.4645e-05 - acc: 1.0000\n",
      "Epoch 20/20\n",
      "140/140 [==============================] - 15s 104ms/step - loss: 5.4636e-05 - acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fdfd4b424c0>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_pad, train_df['class'], epochs=20, batch_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde0c81c",
   "metadata": {},
   "source": [
    "#### ii. Report the train and test accuracies of this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2e4db8b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - 2s 32ms/step - loss: 2.4240e-05 - acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.424046215310227e-05, 1.0]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(train_pad,  train_df['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7e0903ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 1s 31ms/step - loss: 1.6201 - acc: 0.7650\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.620126485824585, 0.7649999856948853]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_pad,  test_df['class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6821e9c",
   "metadata": {},
   "source": [
    "#### The train accuracy is 1.0000 and test accuracy is 0.7700 after 25 epochs. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8543e4fb",
   "metadata": {},
   "source": [
    "#### The training accuracy is close to one after about 6-7 epochs, which means there is a probability of overfitting. In this situation, I would slightly modify this model in the following to add a early stop to determine the number of epochs and see if the test accuracy would increase. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "475589af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_3 (Embedding)     (None, 730, 32)           160032    \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 32)                8320      \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 256)               8448      \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 177,057\n",
      "Trainable params: 177,057\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "140/140 [==============================] - 19s 123ms/step - loss: 0.6893 - acc: 0.5379\n",
      "Epoch 2/50\n",
      "140/140 [==============================] - 16s 113ms/step - loss: 0.5158 - acc: 0.7586\n",
      "Epoch 3/50\n",
      "140/140 [==============================] - 15s 104ms/step - loss: 0.1892 - acc: 0.9329\n",
      "Epoch 4/50\n",
      "140/140 [==============================] - 15s 104ms/step - loss: 0.0774 - acc: 0.9786\n",
      "Epoch 5/50\n",
      "140/140 [==============================] - 15s 104ms/step - loss: 0.0332 - acc: 0.9893\n",
      "Epoch 6/50\n",
      "140/140 [==============================] - 15s 104ms/step - loss: 0.0263 - acc: 0.9907\n",
      "Epoch 7/50\n",
      "140/140 [==============================] - 18s 128ms/step - loss: 0.0164 - acc: 0.9957\n",
      "Epoch 8/50\n",
      "140/140 [==============================] - 21s 151ms/step - loss: 0.0532 - acc: 0.9829\n",
      "Epoch 9/50\n",
      "140/140 [==============================] - 18s 125ms/step - loss: 0.0145 - acc: 0.9964\n",
      "Epoch 10/50\n",
      "140/140 [==============================] - 18s 130ms/step - loss: 8.7470e-04 - acc: 1.0000\n",
      "Epoch 11/50\n",
      "140/140 [==============================] - 20s 143ms/step - loss: 4.6023e-04 - acc: 1.0000\n",
      "Epoch 12/50\n",
      "140/140 [==============================] - 20s 143ms/step - loss: 2.4149e-04 - acc: 1.0000\n",
      "Epoch 13/50\n",
      "140/140 [==============================] - 19s 138ms/step - loss: 1.7214e-04 - acc: 1.0000\n",
      "Epoch 14/50\n",
      "140/140 [==============================] - 19s 138ms/step - loss: 1.2900e-04 - acc: 1.0000\n",
      "Epoch 15/50\n",
      "140/140 [==============================] - 18s 126ms/step - loss: 1.0750e-04 - acc: 1.0000\n",
      "Epoch 16/50\n",
      "140/140 [==============================] - 18s 130ms/step - loss: 8.0615e-05 - acc: 1.0000\n",
      "Epoch 17/50\n",
      "140/140 [==============================] - 18s 129ms/step - loss: 6.3286e-05 - acc: 1.0000\n",
      "Epoch 18/50\n",
      "140/140 [==============================] - 18s 131ms/step - loss: 6.4179e-05 - acc: 1.0000\n",
      "Epoch 19/50\n",
      "140/140 [==============================] - 17s 122ms/step - loss: 4.7970e-05 - acc: 1.0000\n",
      "Epoch 20/50\n",
      "140/140 [==============================] - 17s 118ms/step - loss: 4.7751e-05 - acc: 1.0000\n",
      "Epoch 21/50\n",
      "140/140 [==============================] - 21s 147ms/step - loss: 3.8523e-05 - acc: 1.0000\n",
      "Epoch 22/50\n",
      "140/140 [==============================] - 18s 128ms/step - loss: 3.2564e-05 - acc: 1.0000\n",
      "Epoch 23/50\n",
      "140/140 [==============================] - 17s 120ms/step - loss: 3.0541e-05 - acc: 1.0000\n",
      "Epoch 24/50\n",
      "140/140 [==============================] - 19s 134ms/step - loss: 2.5081e-05 - acc: 1.0000\n",
      "Epoch 25/50\n",
      "140/140 [==============================] - 17s 124ms/step - loss: 2.1873e-05 - acc: 1.0000\n",
      "Epoch 26/50\n",
      "140/140 [==============================] - 17s 121ms/step - loss: 2.1398e-05 - acc: 1.0000\n",
      "Epoch 27/50\n",
      "140/140 [==============================] - 20s 142ms/step - loss: 1.3228e-05 - acc: 1.0000\n",
      "Epoch 28/50\n",
      "140/140 [==============================] - 20s 145ms/step - loss: 1.3760e-05 - acc: 1.0000\n",
      "Epoch 29/50\n",
      "140/140 [==============================] - 19s 138ms/step - loss: 1.5045e-05 - acc: 1.0000\n",
      "Epoch 30/50\n",
      "140/140 [==============================] - 21s 153ms/step - loss: 1.0887e-05 - acc: 1.0000\n",
      "Epoch 31/50\n",
      "140/140 [==============================] - 24s 171ms/step - loss: 1.0156e-05 - acc: 1.0000\n",
      "Epoch 32/50\n",
      "140/140 [==============================] - 23s 161ms/step - loss: 8.5363e-06 - acc: 1.0000\n",
      "Epoch 33/50\n",
      "140/140 [==============================] - 24s 170ms/step - loss: 7.7247e-06 - acc: 1.0000\n",
      "Epoch 34/50\n",
      "140/140 [==============================] - 21s 150ms/step - loss: 6.8641e-06 - acc: 1.0000\n",
      "Epoch 35/50\n",
      "140/140 [==============================] - 19s 139ms/step - loss: 6.4370e-06 - acc: 1.0000\n",
      "Epoch 36/50\n",
      "140/140 [==============================] - 20s 139ms/step - loss: 7.5759e-06 - acc: 1.0000\n",
      "Epoch 37/50\n",
      "140/140 [==============================] - 20s 139ms/step - loss: 4.5042e-06 - acc: 1.0000\n",
      "Epoch 38/50\n",
      "140/140 [==============================] - 19s 138ms/step - loss: 5.8028e-06 - acc: 1.0000\n",
      "Epoch 39/50\n",
      "140/140 [==============================] - 19s 136ms/step - loss: 4.8978e-06 - acc: 1.0000\n",
      "Epoch 40/50\n",
      "140/140 [==============================] - 19s 135ms/step - loss: 3.8738e-06 - acc: 1.0000\n",
      "Epoch 41/50\n",
      "140/140 [==============================] - 19s 136ms/step - loss: 3.2348e-06 - acc: 1.0000\n",
      "Epoch 42/50\n",
      "140/140 [==============================] - 18s 131ms/step - loss: 2.8790e-06 - acc: 1.0000\n",
      "Epoch 43/50\n",
      "140/140 [==============================] - 18s 128ms/step - loss: 3.0683e-06 - acc: 1.0000\n",
      "Epoch 44/50\n",
      "140/140 [==============================] - 18s 128ms/step - loss: 2.9276e-06 - acc: 1.0000\n",
      "Epoch 45/50\n",
      "140/140 [==============================] - 18s 128ms/step - loss: 2.6972e-06 - acc: 1.0000\n",
      "Epoch 46/50\n",
      "140/140 [==============================] - 16s 116ms/step - loss: 3.0201e-06 - acc: 1.0000\n",
      "Epoch 47/50\n",
      "140/140 [==============================] - 17s 118ms/step - loss: 2.4644e-06 - acc: 1.0000\n",
      "Epoch 48/50\n",
      "140/140 [==============================] - 16s 115ms/step - loss: 2.7203e-06 - acc: 1.0000\n",
      "Epoch 49/50\n",
      "140/140 [==============================] - 16s 116ms/step - loss: 2.2083e-06 - acc: 1.0000\n",
      "Epoch 50/50\n",
      "140/140 [==============================] - 17s 119ms/step - loss: 1.3956e-06 - acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fdfd71fa910>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "embedding_layer = Embedding(5001, 32, input_length=730)\n",
    "model.add(embedding_layer)\n",
    "\n",
    "# model.add(Flatten())\n",
    "model.add(LSTM(32))\n",
    "model.add(Dropout(0.20))\n",
    "model.add(Dense(256,activation='ReLU'))\n",
    "model.add(Dropout(0.20))\n",
    "\n",
    "callback = EarlyStopping(monitor='loss', patience=3)\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['acc'],)\n",
    "print(model.summary())\n",
    "model.fit(train_pad, train_df['class'], epochs=50, batch_size=10, callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "505c06e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 1s 48ms/step - loss: 2.3737 - acc: 0.7667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.3737261295318604, 0.7666666507720947]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_pad,  test_df['class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462dce46",
   "metadata": {},
   "source": [
    "#### Here, after I ran the model for several times with different number of epochs, the test accuracy increases slowly (from 74% to about 78%) if I increased the number of epochs from  6 to 50. I would guess the test accuracy would keep increasing after 50 epochs. Also, in most situation, the early stop with 3 patience rarely make effects. This may because the model is slowly inproving and getting stable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87376ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd20169a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
